{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on DARPA E3 Trace Dataset: \n",
    "\n",
    "This notebook is specifically designed for the evaluation of Flash on the DARPA E3 Trace dataset. Notably, the Trace dataset is characterized as a node-level dataset. In our analysis, Flash is configured to operate in a node-level setting to aptly assess this dataset. A key aspect to note is that the Trace dataset lacks certain essential node attributes for specific node types. This limitation means that Flash cannot be operated in a decoupled mode with offline GNN embeddings for this dataset. Consequently, we employ an online GNN coupled with word2vec semantic embeddings to achieve effective evaluation results for this dataset.\n",
    "\n",
    "## Dataset Access: \n",
    "- Access the Trace dataset via the following link: [Trace Dataset](https://drive.google.com/drive/folders/1QlbUFWAGq3Hpl8wVdzOdIoZLFxkII4EK).\n",
    "- The dataset files will be downloaded automatically by the script.\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- The script is designed to automatically parse the downloaded data files.\n",
    "- Execute all cells within this notebook to obtain the evaluation results.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- The notebook is configured to use pre-trained model weights by default.\n",
    "- It also provides the option to set parameters for independently training Graph Neural Networks (GNNs) and word2vec models.\n",
    "- These newly trained models can then be utilized for a comprehensive evaluation of the dataset.\n",
    "\n",
    "Adhere to these steps for a detailed and effective analysis of the Trace dataset using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:42.837955Z",
     "iopub.status.busy": "2025-12-17T14:53:42.837540Z",
     "iopub.status.idle": "2025-12-17T14:53:46.324224Z",
     "shell.execute_reply": "2025-12-17T14:53:46.323133Z"
    },
    "id": "F1op-CbyLuN4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "import csv\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "import subprocess\n",
    "gpu_mem = {int(x.split(',')[0]): int(x.split(',')[1]) for x in subprocess.check_output(\n",
    "    [\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"], \n",
    "    encoding='utf-8').strip().split('\\n')}\n",
    "best_gpu = max(gpu_mem.items(), key=lambda x: x[1])[0]\n",
    "device = torch.device(f'cuda:{best_gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.358092Z",
     "iopub.status.busy": "2025-12-17T14:53:46.357105Z",
     "iopub.status.idle": "2025-12-17T14:53:46.362155Z",
     "shell.execute_reply": "2025-12-17T14:53:46.361486Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# urls = [\"https://drive.google.com/file/d/1GG1aUnPjjzzdbxznVTN8X6oVfA-K4oIV/view?usp=drive_link\"]\n",
    "# for url in urls:\n",
    "#     gdown.download(url, quiet=False, use_cookies=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.363679Z",
     "iopub.status.busy": "2025-12-17T14:53:46.363522Z",
     "iopub.status.idle": "2025-12-17T14:53:46.366066Z",
     "shell.execute_reply": "2025-12-17T14:53:46.365665Z"
    }
   },
   "outputs": [],
   "source": [
    "Train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.367412Z",
     "iopub.status.busy": "2025-12-17T14:53:46.367258Z",
     "iopub.status.idle": "2025-12-17T14:53:46.369842Z",
     "shell.execute_reply": "2025-12-17T14:53:46.369437Z"
    },
    "id": "nM7KaeCbA_mQ"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.371287Z",
     "iopub.status.busy": "2025-12-17T14:53:46.371131Z",
     "iopub.status.idle": "2025-12-17T14:53:46.385579Z",
     "shell.execute_reply": "2025-12-17T14:53:46.385068Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_uuid(line):\n",
    "    pattern_uuid = re.compile(r'uuid\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_uuid.findall(line)\n",
    "\n",
    "def extract_subject_type(line):\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_type.findall(line)\n",
    "\n",
    "def show(file_path):\n",
    "    print(f\"Processing {file_path}\")\n",
    "\n",
    "def extract_edge_info(line):\n",
    "    pattern_src = re.compile(r'subject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst1 = re.compile(r'predicateObject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst2 = re.compile(r'predicateObject2\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    pattern_time = re.compile(r'timestampNanos\\\":(.*?),')\n",
    "\n",
    "    edge_type = extract_subject_type(line)[0]\n",
    "    timestamp = pattern_time.findall(line)[0]\n",
    "    src_id = pattern_src.findall(line)\n",
    "\n",
    "    if len(src_id) == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    src_id = src_id[0]\n",
    "    dst_id1 = pattern_dst1.findall(line)\n",
    "    dst_id2 = pattern_dst2.findall(line)\n",
    "\n",
    "    if len(dst_id1) > 0 and dst_id1[0] != 'null':\n",
    "        dst_id1 = dst_id1[0]\n",
    "    else:\n",
    "        dst_id1 = None\n",
    "\n",
    "    if len(dst_id2) > 0 and dst_id2[0] != 'null':\n",
    "        dst_id2 = dst_id2[0]\n",
    "    else:\n",
    "        dst_id2 = None\n",
    "\n",
    "    return src_id, edge_type, timestamp, dst_id1, dst_id2\n",
    "\n",
    "def process_data(file_path):\n",
    "    id_nodetype_map = {}\n",
    "    notice_num = 1000000\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f:\n",
    "            show(now_path)\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line or 'com.bbn.tc.schema.avro.cdm18.Host' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.TimeMarker' in line or 'com.bbn.tc.schema.avro.cdm18.StartMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.UnitDependency' in line or 'com.bbn.tc.schema.avro.cdm18.EndMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                uuid = extract_uuid(line)[0]\n",
    "                subject_type = extract_subject_type(line)\n",
    "\n",
    "                if len(subject_type) < 1:\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.MemoryObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'MemoryObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.NetFlowObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'NetFlowObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.UnnamedPipeObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'UnnamedPipeObject'\n",
    "                        continue\n",
    "\n",
    "                id_nodetype_map[uuid] = subject_type[0]\n",
    "\n",
    "    return id_nodetype_map\n",
    "\n",
    "def process_edges(file_path, id_nodetype_map):\n",
    "    notice_num = 1000000\n",
    "    not_in_cnt = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f, open(now_path+'.txt', 'w') as fw:\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line:\n",
    "                    src_id, edge_type, timestamp, dst_id1, dst_id2 = extract_edge_info(line)\n",
    "\n",
    "                    if src_id is None or src_id not in id_nodetype_map:\n",
    "                        not_in_cnt += 1\n",
    "                        continue\n",
    "\n",
    "                    src_type = id_nodetype_map[src_id]\n",
    "\n",
    "                    if dst_id1 is not None and dst_id1 in id_nodetype_map:\n",
    "                        dst_type1 = id_nodetype_map[dst_id1]\n",
    "                        this_edge1 = f\"{src_id}\\t{src_type}\\t{dst_id1}\\t{dst_type1}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge1)\n",
    "\n",
    "                    if dst_id2 is not None and dst_id2 in id_nodetype_map:\n",
    "                        dst_type2 = id_nodetype_map[dst_id2]\n",
    "                        this_edge2 = f\"{src_id}\\t{src_type}\\t{dst_id2}\\t{dst_type2}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge2)\n",
    "\n",
    "def run_data_processing():\n",
    "    os.system('tar -zxvf ta1-trace-e3-official-1.json.tar.gz')\n",
    "\n",
    "    path_list = ['ta1-trace-e3-official-1.json']\n",
    "\n",
    "    for path in path_list:\n",
    "        id_nodetype_map = process_data(path)\n",
    "\n",
    "        process_edges(path, id_nodetype_map)\n",
    "\n",
    "    os.system('cp ta1-trace-e3-official-1.json.txt trace_train.txt')\n",
    "    os.system('cp ta1-trace-e3-official-1.json.4.txt trace_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.387218Z",
     "iopub.status.busy": "2025-12-17T14:53:46.387050Z",
     "iopub.status.idle": "2025-12-17T14:53:46.389422Z",
     "shell.execute_reply": "2025-12-17T14:53:46.389040Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.390877Z",
     "iopub.status.busy": "2025-12-17T14:53:46.390728Z",
     "iopub.status.idle": "2025-12-17T14:53:46.401943Z",
     "shell.execute_reply": "2025-12-17T14:53:46.401436Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_node_properties(nodes, node_id, properties):\n",
    "    if node_id not in nodes:\n",
    "        nodes[node_id] = []\n",
    "    nodes[node_id].extend(properties)\n",
    "\n",
    "def update_edge_index(edges, edge_index, index):\n",
    "    for src_id, dst_id in edges:\n",
    "        src = index[src_id]\n",
    "        dst = index[dst_id]\n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)\n",
    "\n",
    "def prepare_graph(df):\n",
    "    nodes, labels, edges = {}, {}, []\n",
    "    dummies = {\"SUBJECT_PROCESS\":0, \"MemoryObject\":1, \"FILE_OBJECT_CHAR\":2, \"FILE_OBJECT_FILE\":3,\n",
    "               \"FILE_OBJECT_DIR\":4, \"SUBJECT_UNIT\":5, \"UnnamedPipeObject\":6, \"FILE_OBJECT_UNIX_SOCKET\":7, \n",
    "               \"SRCSINK_UNKNOWN\":8, \"FILE_OBJECT_LINK\":9, \"NetFlowObject\":10, \"FILE_OBJECT_BLOCK\":11}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        action = row[\"action\"]\n",
    "        properties = [row['exec'], action] + ([row['path']] if row['path'] else [])\n",
    "        \n",
    "        actor_id = row[\"actorID\"]\n",
    "        add_node_properties(nodes, actor_id, properties)\n",
    "        labels[actor_id] = dummies[row['actor_type']]\n",
    "\n",
    "        object_id = row[\"objectID\"]\n",
    "        add_node_properties(nodes, object_id, properties)\n",
    "        labels[object_id] = dummies[row['object']]\n",
    "\n",
    "        edges.append((actor_id, object_id))\n",
    "\n",
    "    features, feat_labels, edge_index, index_map = [], [], [[], []], {}\n",
    "    for node_id, props in nodes.items():\n",
    "        features.append(props)\n",
    "        feat_labels.append(labels[node_id])\n",
    "        index_map[node_id] = len(features) - 1\n",
    "\n",
    "    update_edge_index(edges, edge_index, index_map)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(index_map.keys()), index_map\n",
    "\n",
    "dummies = {\"SUBJECT_PROCESS\":0, \"MemoryObject\":1, \"FILE_OBJECT_CHAR\":2, \"FILE_OBJECT_FILE\":3,\n",
    "               \"FILE_OBJECT_DIR\":4, \"SUBJECT_UNIT\":5, \"UnnamedPipeObject\":6, \"FILE_OBJECT_UNIX_SOCKET\":7, \n",
    "               \"SRCSINK_UNKNOWN\":8, \"FILE_OBJECT_LINK\":9, \"NetFlowObject\":10, \"FILE_OBJECT_BLOCK\":11}\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def add_csv_edges_efficient(original_features, original_labels, original_edge_index, original_mapp, original_mapidx, csv_path, thres=450): \n",
    "    csv_edges = []\n",
    "    csv_nodes = set()\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            src_id, dst_id = row[0], row[1]\n",
    "            csv_edges.append((src_id, dst_id))\n",
    "            csv_nodes.add(src_id)\n",
    "            csv_nodes.add(dst_id)\n",
    "    \n",
    "    extended_features = original_features.copy()\n",
    "    extended_labels = original_labels.copy()\n",
    "    extended_edge_index = [original_edge_index[0].copy(), original_edge_index[1].copy()]\n",
    "    extended_mapp = original_mapp.copy()\n",
    "    extended_mapidx = original_mapidx.copy()\n",
    "\n",
    "    degrees = defaultdict(int)\n",
    "    for src_idx in extended_edge_index[0]:\n",
    "        degrees[src_idx] += 1\n",
    "    for dst_idx in extended_edge_index[1]:\n",
    "        degrees[dst_idx] += 1\n",
    "    \n",
    "    all_degrees = list(degrees.values())\n",
    "    all_degrees.sort(reverse=True)\n",
    "    print(all_degrees[:3000])\n",
    "\n",
    "    count1, count2, count3 = 0, 0, 0\n",
    "    for src_id, dst_id in csv_edges:\n",
    "        if src_id in extended_mapidx and dst_id in extended_mapidx:\n",
    "            src_idx = extended_mapidx[src_id]\n",
    "            dst_idx = extended_mapidx[dst_id]\n",
    "            if degrees[src_idx] <= thres and degrees[dst_idx] <= thres:\n",
    "                extended_edge_index[0].append(src_idx)\n",
    "                extended_edge_index[1].append(dst_idx)\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1\n",
    "        else:\n",
    "            count3 += 1\n",
    "    print(f'Sucessfully add edges: {count1}\\tPrune edges: {count2}\\tFail to add edges: {count3}')\n",
    "    \n",
    "    return extended_features, extended_labels, extended_edge_index, extended_mapp, extended_mapidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.403475Z",
     "iopub.status.busy": "2025-12-17T14:53:46.403315Z",
     "iopub.status.idle": "2025-12-17T14:53:46.407718Z",
     "shell.execute_reply": "2025-12-17T14:53:46.407264Z"
    },
    "id": "fmXWs1dKIzD8"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 2, normalize=True)\n",
    "        self.conv2 = SAGEConv(2, out_channel, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.409110Z",
     "iopub.status.busy": "2025-12-17T14:53:46.408954Z",
     "iopub.status.idle": "2025-12-17T14:53:46.412305Z",
     "shell.execute_reply": "2025-12-17T14:53:46.411885Z"
    },
    "id": "YBuP_tSq94f4"
   },
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.413701Z",
     "iopub.status.busy": "2025-12-17T14:53:46.413548Z",
     "iopub.status.idle": "2025-12-17T14:53:46.490836Z",
     "shell.execute_reply": "2025-12-17T14:53:46.490019Z"
    },
    "id": "3PCP6SXwZaif"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('word2vec_trace_E3.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.494025Z",
     "iopub.status.busy": "2025-12-17T14:53:46.493859Z",
     "iopub.status.idle": "2025-12-17T14:53:46.497253Z",
     "shell.execute_reply": "2025-12-17T14:53:46.496811Z"
    },
    "id": "P8oBL8LFaeOf"
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.498671Z",
     "iopub.status.busy": "2025-12-17T14:53:46.498499Z",
     "iopub.status.idle": "2025-12-17T14:53:46.500928Z",
     "shell.execute_reply": "2025-12-17T14:53:46.500543Z"
    },
    "id": "Se7Ei4tAapVj"
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.502288Z",
     "iopub.status.busy": "2025-12-17T14:53:46.502127Z",
     "iopub.status.idle": "2025-12-17T14:53:46.508659Z",
     "shell.execute_reply": "2025-12-17T14:53:46.508220Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_attributes(d,p):\n",
    "    \n",
    "    f = open(p)\n",
    "    data = [json.loads(x) for x in f if \"EVENT\" in x]\n",
    "\n",
    "    info = []\n",
    "    for x in data:\n",
    "        try:\n",
    "            action = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['type']\n",
    "        except:\n",
    "            action = ''\n",
    "        try:\n",
    "            actor = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['subject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            actor = ''\n",
    "        try:\n",
    "            obj = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            obj = ''\n",
    "        try:\n",
    "            timestamp = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['timestampNanos']\n",
    "        except:\n",
    "            timestamp = ''\n",
    "        try:\n",
    "            cmd = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['properties']['map']['exec']\n",
    "        except:\n",
    "            cmd = ''\n",
    "        try:\n",
    "            path = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObjectPath']['string']\n",
    "        except:\n",
    "            path = ''\n",
    "        try:\n",
    "            path2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2Path']['string']\n",
    "        except:\n",
    "            path2 = ''\n",
    "        try:\n",
    "            obj2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "            info.append({'actorID':actor,'objectID':obj2,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path2})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        info.append({'actorID':actor,'objectID':obj,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path})\n",
    "\n",
    "    rdf = pd.DataFrame.from_records(info).astype(str)\n",
    "    d = d.astype(str)\n",
    "\n",
    "    return d.merge(rdf,how='inner',on=['actorID','objectID','action','timestamp']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:53:46.510045Z",
     "iopub.status.busy": "2025-12-17T14:53:46.509887Z",
     "iopub.status.idle": "2025-12-17T14:57:55.995605Z",
     "shell.execute_reply": "2025-12-17T14:57:55.994816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236540, 236232, 228452, 223904, 197244, 126732, 108947, 108385, 94796, 38176, 35159, 33395, 29137, 26663, 21425, 19007, 17777, 17224, 16195, 15041, 15025, 15002, 14670, 14619, 13779, 13343, 12718, 12660, 12507, 12234, 11855, 11397, 10962, 10838, 10306, 9987, 9187, 8858, 8015, 7518, 7465, 7338, 7266, 7250, 7198, 7120, 7048, 7031, 7022, 6949, 6913, 6664, 6658, 6579, 6476, 6198, 6183, 6084, 5838, 5489, 5453, 4918, 4807, 4687, 4500, 4374, 4297, 4109, 4083, 4071, 3830, 3774, 3738, 3703, 3612, 3505, 3247, 3215, 3125, 3090, 3036, 2966, 2959, 2935, 2574, 2569, 2567, 2556, 2509, 2505, 2483, 2354, 2299, 2233, 2212, 2200, 2197, 2142, 2139, 2130, 2045, 2041, 1994, 1931, 1913, 1896, 1879, 1854, 1783, 1716, 1657, 1645, 1616, 1558, 1500, 1437, 1426, 1405, 1360, 1353, 1339, 1335, 1323, 1321, 1313, 1287, 1283, 1283, 1246, 1237, 1237, 1235, 1234, 1234, 1198, 1188, 1177, 1164, 1161, 1147, 1126, 1122, 1120, 1118, 1066, 1052, 1049, 1043, 1038, 997, 974, 959, 946, 945, 916, 905, 900, 887, 866, 858, 849, 847, 843, 842, 842, 841, 841, 841, 841, 841, 841, 840, 840, 840, 838, 838, 827, 795, 747, 741, 739, 739, 738, 736, 736, 734, 733, 732, 732, 731, 731, 731, 730, 730, 729, 728, 728, 728, 728, 727, 727, 727, 726, 726, 724, 724, 724, 723, 721, 721, 720, 718, 716, 716, 714, 711, 708, 702, 702, 688, 682, 677, 676, 676, 675, 669, 656, 652, 644, 624, 617, 617, 616, 616, 615, 615, 615, 615, 615, 615, 614, 614, 605, 591, 589, 582, 566, 562, 560, 558, 557, 553, 552, 536, 512, 511, 509, 509, 507, 507, 507, 506, 506, 505, 505, 504, 504, 502, 500, 499, 499, 498, 498, 497, 491, 488, 486, 484, 483, 481, 474, 474, 470, 470, 469, 468, 468, 466, 464, 459, 456, 456, 455, 446, 444, 440, 436, 434, 430, 416, 415, 413, 411, 411, 410, 410, 410, 410, 410, 410, 410, 410, 410, 410, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 407, 407, 407, 406, 406, 406, 406, 405, 400, 394, 393, 389, 388, 388, 384, 383, 383, 381, 379, 379, 378, 378, 378, 378, 378, 378, 377, 377, 377, 376, 376, 375, 375, 373, 373, 372, 372, 372, 372, 372, 372, 366, 353, 350, 349, 347, 346, 342, 341, 338, 336, 331, 329, 328, 328, 327, 327, 326, 326, 326, 325, 325, 325, 325, 325, 325, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 324, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 323, 322, 321, 320, 319, 319, 319, 318, 318, 318, 317, 316, 316, 315, 313, 312, 311, 311, 309, 308, 307, 307, 307, 306, 306, 306, 306, 305, 305, 305, 305, 305, 305, 304, 303, 303, 302, 302, 302, 301, 300, 299, 297, 288, 288, 287, 285, 284, 284, 284, 284, 284, 282, 280, 279, 278, 277, 274, 274, 273, 272, 272, 272, 272, 270, 269, 269, 268, 268, 268, 268, 267, 266, 260, 260, 258, 256, 256, 256, 256, 255, 255, 252, 252, 251, 250, 249, 249, 249, 249, 249, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 247, 246, 245, 244, 244, 244, 236, 235, 234, 233, 233, 232, 231, 231, 230, 230, 229, 229, 229, 229, 229, 229, 229, 228, 228, 228, 228, 227, 227, 227, 227, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 225, 225, 224, 224, 223, 223, 223, 223, 223, 223, 223, 223, 222, 221, 221, 220, 219, 216, 215, 214, 214, 214, 213, 212, 211, 210, 210, 210, 209, 209, 209, 206, 206, 206, 206, 206, 206, 205, 205, 205, 205, 205, 205, 204, 204, 204, 204, 203, 203, 203, 203, 203, 202, 202, 201, 201, 201, 201, 201, 200, 200, 200, 200, 200, 200, 199, 199, 199, 199, 199, 199, 199, 197, 197, 197, 196, 196, 195, 195, 194, 194, 193, 192, 192, 191, 191, 189, 188, 187, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 183, 182, 182, 181, 180, 179, 178, 176, 176, 175, 174, 172, 172, 171, 171, 171, 170, 168, 168, 168, 167, 167, 166, 164, 164, 164, 164, 164, 164, 164, 164, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 162, 162, 162, 162, 162, 162, 162, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 159, 158, 157, 157, 157, 157, 155, 155, 154, 153, 153, 153, 152, 152, 152, 150, 149, 149, 149, 149, 149, 149, 147, 147, 146, 145, 144, 144, 144, 144, 143, 143, 142, 141, 141, 140, 140, 140, 139, 139, 139, 139, 139, 139, 138, 138, 138, 138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 135, 135, 135, 135, 135, 135, 134, 134, 134, 134, 134, 133, 133, 133, 133, 132, 132, 132, 132, 131, 131, 131, 130, 129, 129, 129, 129, 127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 125, 125, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 123, 123, 123, 123, 123, 122, 122, 122, 122, 121, 121, 121, 121, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 119, 119, 119, 119, 118, 118, 118, 118, 118, 118, 118, 118, 118, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 116, 116, 116, 116, 115, 115, 115, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 113, 113, 113, 113, 113, 113, 113, 112, 112, 112, 112, 112, 111, 111, 111, 111, 111, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 105, 105, 105, 105, 105, 105, 105, 104, 104, 104, 104, 104, 104, 104, 104, 103, 103, 103, 103, 102, 102, 102, 102, 102, 102, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 99, 99, 99, 99, 98, 98, 98, 98, 98, 98, 98, 97, 97, 97, 97, 97, 97, 97, 97, 97, 96, 96, 96, 96, 96, 96, 96, 96, 96, 95, 95, 95, 94, 94, 94, 94, 94, 94, 94, 94, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 92, 92, 92, 92, 92, 92, 92, 92, 91, 91, 90, 90, 90, 90, 89, 89, 89, 89, 89, 89, 89, 89, 88, 88, 88, 88, 88, 88, 88, 88, 88, 87, 87, 87, 87, 87, 87, 87, 87, 87, 86, 86, 86, 86, 86, 86, 86, 85, 85, 85, 85, 84, 84, 84, 84, 84, 84, 84, 83, 83, 83, 83, 83, 83, 82, 81, 81, 81, 81, 81, 81, 80, 80, 80, 80, 80, 80, 79, 79, 79, 79, 79, 79, 79, 79, 78, 78, 78, 78, 78, 78, 78, 77, 77, 77, 77, 77, 77, 77, 77, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42]\n",
      "Sucessfully add edges: 1067\tPrune edges: 3319\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "if Train:\n",
    "    f = open(\"../trace_train.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df = df.dropna()\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = add_attributes(df,\"../ta1-trace-e3-official-1.json\")\n",
    "    phrases,labels,edges,mapp,mapidx = prepare_graph(df)\n",
    "    csv_path = \"../../flash-add-edge/trace_train.csv\"\n",
    "    phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "        phrases, labels, edges, mapp, mapidx, csv_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:57:55.997814Z",
     "iopub.status.busy": "2025-12-17T14:57:55.997513Z",
     "iopub.status.idle": "2025-12-17T14:57:56.284616Z",
     "shell.execute_reply": "2025-12-17T14:57:56.283750Z"
    },
    "id": "p3TAi69zI1bO"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# model = GCN(30,11).to(device)\n",
    "model = GCN(4,11).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:57:56.287730Z",
     "iopub.status.busy": "2025-12-17T14:57:56.287555Z",
     "iopub.status.idle": "2025-12-17T14:57:56.290160Z",
     "shell.execute_reply": "2025-12-17T14:57:56.289752Z"
    },
    "id": "3RDmGME5iPb5"
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:57:56.292232Z",
     "iopub.status.busy": "2025-12-17T14:57:56.292082Z",
     "iopub.status.idle": "2025-12-17T14:57:56.294181Z",
     "shell.execute_reply": "2025-12-17T14:57:56.293809Z"
    }
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=4, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T14:57:56.296089Z",
     "iopub.status.busy": "2025-12-17T14:57:56.295945Z",
     "iopub.status.idle": "2025-12-17T14:57:56.688419Z",
     "shell.execute_reply": "2025-12-17T14:57:56.687755Z"
    },
    "id": "Vn_pMyt5Jd-6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000):\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "\n",
    "def infer(document):\n",
    "    word_embeddings = [w2vmodel.wv[word] for word in document if word in w2vmodel.wv]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(4)\n",
    "    \n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    mean_embedding = np.mean(output_embedding, axis=0)\n",
    "    \n",
    "    return mean_embedding\n",
    "\n",
    "# encoder = PositionalEncoder(30)\n",
    "encoder = PositionalEncoder(4)\n",
    "# w2vmodel = Word2Vec.load(\"trained_weights/trace/word2vec_trace_E3.model\")\n",
    "w2vmodel = Word2Vec.load(\"../word2vec_trace_E3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-17T14:57:56.691227Z",
     "iopub.status.busy": "2025-12-17T14:57:56.691049Z",
     "iopub.status.idle": "2025-12-17T15:00:26.741286Z",
     "shell.execute_reply": "2025-12-17T15:00:26.740390Z"
    },
    "executionInfo": {
     "elapsed": 503992,
     "status": "ok",
     "timestamp": 1673553696499,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "ae20b63a-34d6-45ac-a91e-d659f8fc957f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3435254332996838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 1025513 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3211567377693374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 644032 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3099905318144383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 2. 214520 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3629300404057316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 3. 158432 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3627749283466404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 4. 154747 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3488932996338314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 5. 100222 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3469014435697884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 6. 95070 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3482819196866163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 7. 87379 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3419036049150272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 8. 84632 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3419465966841733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 9. 79959 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3385518468916136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 79880 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.336605976030238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 77194 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3347213340367103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 76981 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3330652874082016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 75516 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3302585974456433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 14. 74461 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3261607449466584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 73498 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3285663928942517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 72764 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32784917404257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 70124 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3247946695731727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 68575 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3306015535640405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 61331 nodes still misclassified \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "if Train:\n",
    "    l = np.array(labels)\n",
    "    ngram_class_weights = [\n",
    "        0.8076,  \n",
    "        0.7991,   \n",
    "        0.9089,   \n",
    "        0.8287,   \n",
    "        0.8897,   \n",
    "        0.7465,   \n",
    "        0.7880,   \n",
    "        0.5000,   \n",
    "        0.8853,   \n",
    "        1.0000,   \n",
    "        1.5000    \n",
    "    ]\n",
    "    \n",
    "    class_weights = torch.tensor(ngram_class_weights,dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for m_n in range(20):\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      total_loss = 0\n",
    "      for subg in loader:\n",
    "          model.train()\n",
    "          optimizer.zero_grad() \n",
    "          out = model(subg.x, subg.edge_index) \n",
    "          loss = criterion(out, subg.y) \n",
    "          loss.backward() \n",
    "          optimizer.step()      \n",
    "          total_loss += loss.item() * subg.batch_size\n",
    "      print(total_loss / mask.sum().item())\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      for subg in loader:\n",
    "          model.eval()\n",
    "          out = model(subg.x, subg.edge_index)\n",
    "\n",
    "          sorted, indices = out.sort(dim=1,descending=True)\n",
    "          conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "          conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "          pred = indices[:,0]\n",
    "          cond = (pred == subg.y) & (conf >= 0.9)\n",
    "          subg.n_id = subg.n_id.to(device)\n",
    "          mask[subg.n_id[cond]] = False\n",
    "\n",
    "      torch.save(model.state_dict(), f'lword2vec_gnn_trace{m_n}_E3.pth')\n",
    "      print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T15:00:26.745516Z",
     "iopub.status.busy": "2025-12-17T15:00:26.745180Z",
     "iopub.status.idle": "2025-12-17T15:00:26.781332Z",
     "shell.execute_reply": "2025-12-17T15:00:26.775011Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def Get_Adjacent(ids, mapp, edges, hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    \n",
    "    neighbors = set()\n",
    "    for edge in zip(edges[0], edges[1]):\n",
    "        if any(mapp[node] in ids for node in edge):\n",
    "            neighbors.update(mapp[node] for node in edge)\n",
    "\n",
    "    if hops > 1:\n",
    "        neighbors = neighbors.union(Get_Adjacent(neighbors, mapp, edges, hops - 1))\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def calculate_metrics(TP, FP, FN, TN):\n",
    "    FPR = FP / (FP + TN) if FP + TN > 0 else 0\n",
    "    TPR = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    prec = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    rec = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    fscore = (2 * prec * rec) / (prec + rec) if prec + rec > 0 else 0\n",
    "\n",
    "    return prec, rec, fscore, FPR, TPR\n",
    "\n",
    "def helper(MP, all_pids, GP, edges, mapp):\n",
    "    TP = MP.intersection(GP)\n",
    "    FP = MP - GP\n",
    "    FN = GP - MP\n",
    "    TN = all_pids - (GP | MP)\n",
    "\n",
    "    two_hop_gp = Get_Adjacent(GP, mapp, edges, 2)\n",
    "    two_hop_tp = Get_Adjacent(TP, mapp, edges, 2)\n",
    "    FPL = FP - two_hop_gp\n",
    "    TPL = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "\n",
    "    TP, FP, FN, TN = len(TPL), len(FPL), len(FN), len(TN)\n",
    "\n",
    "    prec, rec, fscore, FPR, TPR = calculate_metrics(TP, FP, FN, TN)\n",
    "    print(f\"True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN}\")\n",
    "    print(f\"Precision: {round(prec, 2)}, Recall: {round(rec, 2)}, Fscore: {round(fscore, 2)}\")\n",
    "    \n",
    "    return TPL, FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T15:00:26.790659Z",
     "iopub.status.busy": "2025-12-17T15:00:26.790418Z",
     "iopub.status.idle": "2025-12-17T15:06:20.262690Z",
     "shell.execute_reply": "2025-12-17T15:06:20.261410Z"
    },
    "id": "OZFrSLVZ29qU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134478, 32807, 29277, 26626, 24197, 20934, 20914, 20071, 19497, 19471, 19341, 19162, 18978, 18859, 18840, 18630, 17603, 17142, 16633, 16363, 16193, 16136, 16129, 15198, 14946, 14899, 14632, 14627, 14576, 14471, 14383, 13746, 13716, 13286, 13231, 13085, 12939, 12750, 12721, 12656, 12429, 12397, 12390, 12360, 12272, 12159, 11559, 11489, 11379, 11174, 11104, 10858, 10663, 10581, 10570, 10531, 10272, 10177, 10030, 10019, 10018, 9946, 9933, 9864, 9792, 9785, 9719, 9683, 9651, 9620, 9588, 9493, 9445, 9429, 9394, 9256, 9206, 9111, 9069, 8994, 8763, 8632, 8578, 8534, 8514, 8430, 8415, 8406, 8282, 8139, 8116, 7969, 7964, 7900, 7894, 7339, 7281, 7262, 7262, 7249, 7199, 7126, 7051, 6891, 6761, 6741, 6690, 6669, 6626, 6603, 6593, 6582, 6561, 6552, 6442, 6428, 6422, 6374, 6352, 6301, 6284, 6241, 6208, 6206, 6175, 6144, 6096, 6027, 5993, 5974, 5937, 5934, 5880, 5878, 5846, 5846, 5615, 5567, 5358, 5317, 5183, 5075, 5021, 4937, 4831, 4763, 4639, 4393, 4197, 4082, 4077, 3858, 3764, 3745, 3670, 3589, 3514, 3464, 3454, 3424, 3265, 3260, 3240, 3204, 3092, 2979, 2902, 2831, 2773, 2717, 2686, 2678, 2598, 2563, 2455, 2439, 2414, 2412, 2378, 2364, 2338, 2338, 2320, 2308, 2295, 2250, 2245, 2245, 2245, 2245, 2237, 2232, 2222, 2217, 2205, 2176, 2175, 2171, 2168, 2125, 2111, 2048, 2042, 2041, 2005, 1999, 1997, 1996, 1959, 1952, 1939, 1933, 1919, 1907, 1905, 1903, 1862, 1862, 1837, 1815, 1770, 1740, 1697, 1694, 1692, 1690, 1689, 1687, 1684, 1673, 1658, 1653, 1636, 1632, 1604, 1574, 1559, 1557, 1547, 1539, 1535, 1527, 1465, 1434, 1428, 1427, 1426, 1405, 1404, 1392, 1380, 1374, 1374, 1368, 1361, 1360, 1356, 1326, 1316, 1307, 1298, 1288, 1261, 1255, 1247, 1234, 1228, 1224, 1207, 1207, 1199, 1196, 1191, 1188, 1179, 1179, 1173, 1171, 1157, 1154, 1137, 1133, 1131, 1129, 1128, 1105, 1096, 1095, 1086, 1085, 1084, 1084, 1084, 1079, 1079, 1076, 1075, 1075, 1062, 1059, 1056, 1055, 1054, 1053, 1052, 1044, 1041, 1006, 1004, 1004, 969, 968, 964, 957, 956, 939, 919, 915, 886, 870, 858, 857, 854, 849, 844, 838, 801, 797, 792, 790, 770, 755, 750, 749, 739, 737, 737, 733, 733, 731, 731, 731, 730, 729, 729, 727, 725, 723, 722, 720, 717, 717, 713, 711, 708, 705, 702, 702, 682, 679, 672, 665, 664, 663, 661, 660, 659, 653, 652, 648, 648, 646, 639, 634, 633, 632, 630, 627, 620, 619, 618, 618, 618, 617, 617, 617, 617, 617, 616, 616, 615, 615, 615, 614, 614, 614, 614, 614, 614, 614, 614, 588, 587, 586, 586, 579, 570, 568, 560, 559, 558, 557, 554, 553, 552, 550, 546, 546, 545, 544, 543, 542, 540, 528, 528, 524, 523, 523, 521, 521, 518, 514, 512, 512, 511, 510, 508, 508, 508, 508, 507, 507, 507, 507, 507, 507, 506, 506, 506, 506, 506, 504, 501, 500, 500, 498, 498, 498, 497, 497, 497, 497, 496, 495, 494, 494, 494, 494, 493, 493, 490, 489, 489, 488, 483, 482, 478, 474, 469, 469, 469, 469, 469, 468, 468, 468, 468, 467, 467, 467, 467, 467, 467, 466, 466, 466, 466, 465, 465, 464, 459, 458, 454, 453, 453, 449, 448, 445, 441, 441, 441, 440, 436, 434, 434, 432, 430, 430, 429, 427, 425, 425, 419, 419, 418, 418, 417, 414, 413, 412, 412, 410, 410, 410, 410, 410, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 409, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 407, 407, 407, 407, 407, 406, 406, 406, 403, 402, 401, 399, 398, 398, 395, 395, 394, 394, 393, 393, 392, 392, 392, 391, 390, 390, 390, 390, 390, 390, 390, 390, 389, 389, 388, 386, 386, 384, 383, 381, 379, 379, 379, 379, 379, 379, 379, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378, 378, 377, 376, 376, 376, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 375, 374, 374, 372, 371, 369, 369, 368, 364, 362, 360, 356, 350, 346, 344, 340, 340, 340, 338, 337, 337, 336, 336, 336, 334, 332, 332, 330, 326, 325, 325, 325, 324, 324, 324, 324, 323, 323, 323, 323, 323, 323, 323, 323, 322, 322, 318, 318, 318, 317, 317, 316, 315, 315, 315, 315, 315, 314, 313, 313, 313, 312, 312, 311, 310, 310, 310, 310, 309, 309, 309, 309, 308, 308, 308, 308, 308, 306, 306, 306, 306, 306, 306, 306, 305, 305, 305, 305, 305, 305, 305, 305, 305, 304, 304, 304, 304, 303, 302, 300, 300, 299, 298, 297, 297, 297, 297, 297, 297, 297, 296, 296, 296, 296, 296, 296, 296, 296, 296, 295, 295, 295, 294, 293, 293, 293, 293, 293, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 291, 291, 290, 286, 286, 286, 285, 285, 285, 285, 285, 285, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 284, 283, 281, 280, 279, 279, 278, 277, 277, 276, 276, 276, 275, 275, 274, 272, 269, 268, 266, 265, 264, 263, 262, 262, 261, 260, 260, 260, 259, 258, 257, 256, 254, 252, 252, 252, 252, 252, 250, 248, 248, 248, 248, 247, 246, 245, 245, 245, 244, 244, 243, 241, 240, 240, 240, 239, 239, 239, 238, 237, 237, 237, 236, 236, 236, 235, 235, 235, 234, 233, 233, 232, 232, 231, 231, 231, 231, 230, 230, 230, 230, 230, 230, 230, 230, 229, 229, 229, 229, 229, 229, 229, 228, 228, 228, 228, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 227, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 226, 225, 225, 225, 225, 224, 224, 224, 224, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 222, 222, 222, 222, 221, 221, 221, 221, 221, 220, 220, 217, 217, 217, 216, 214, 214, 214, 213, 213, 213, 212, 212, 211, 211, 211, 211, 210, 210, 210, 210, 210, 210, 210, 210, 210, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 208, 208, 208, 208, 208, 208, 208, 207, 207, 207, 206, 206, 206, 206, 206, 206, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 203, 203, 203, 203, 203, 203, 203, 203, 203, 202, 202, 202, 202, 202, 202, 202, 202, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 199, 199, 199, 199, 199, 199, 199, 199, 198, 198, 198, 198, 198, 197, 197, 197, 197, 197, 197, 196, 196, 196, 196, 196, 196, 196, 195, 195, 195, 194, 193, 193, 193, 192, 192, 190, 190, 189, 189, 189, 189, 189, 189, 189, 189, 188, 188, 188, 188, 188, 187, 187, 186, 186, 186, 185, 184, 183, 182, 182, 181, 180, 180, 178, 178, 176, 176, 176, 176, 175, 175, 175, 175, 175, 174, 174, 174, 174, 173, 173, 173, 173, 172, 172, 171, 171, 171, 171, 171, 171, 171, 171, 171, 170, 170, 168, 168, 168, 168, 168, 168, 167, 167, 167, 167, 167, 166, 166, 166, 166, 166, 165, 165, 165, 165, 164, 164, 164, 164, 164, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 160, 159, 159, 159, 159, 159, 159, 158, 158, 158, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 156, 156, 156, 156, 156, 155, 155, 155, 155, 154, 154, 153, 153, 153, 153, 153, 153, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 151, 151, 150, 150, 150, 150, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 147, 146, 146, 146, 146, 145, 145, 145, 144, 144, 144, 144, 144, 144, 143, 143, 143, 142, 142, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 139, 139, 138, 138, 138, 138, 138, 138, 138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 134, 134, 134, 134, 134, 134, 134, 133, 133, 133, 133, 133, 133, 133, 132, 132, 132, 132, 132, 132, 132, 132, 131, 131, 131, 130, 130, 130, 130, 130, 130, 129, 129, 129, 129, 129, 129, 129, 129, 129, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 124, 124, 124, 124, 123, 123, 123, 123, 123, 123, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 121, 121, 121, 121, 121, 121, 121, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 119, 119, 119, 119, 119, 119, 119, 118, 118, 118, 118, 118, 118, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 113, 113, 113, 113, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 99, 99, 99, 99, 99, 99, 99, 98, 98, 98, 98, 98, 98, 98, 98, 97, 97, 97, 97, 97, 97, 97, 97, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 94, 94, 94, 94, 94, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 92, 92, 92, 92, 92, 92, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 83, 83, 83, 83, 83, 83, 83, 83, 83, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69]\n",
      "Sucessfully add edges: 1574\tPrune edges: 3927\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "f = open(\"../trace_test.txt\")\n",
    "data = f.read().split('\\n')\n",
    "data = [line.split('\\t') for line in data]\n",
    "df = pd.DataFrame(data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "df = df.dropna()\n",
    "df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "\n",
    "df = add_attributes(df,\"../ta1-trace-e3-official-1.json.4\")\n",
    "  \n",
    "with open(\"../../data_files/trace.json\", \"r\") as json_file:\n",
    "    GT_mal = set(json.load(json_file))\n",
    "\n",
    "data = df\n",
    "\n",
    "phrases,labels,edges,mapp,mapidx = prepare_graph(data)\n",
    "csv_path = \"../../flash-add-edge/trace_test.csv\"\n",
    "phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "    phrases, labels, edges, mapp, mapidx, csv_path\n",
    ")\n",
    "nodes = []\n",
    "for i, x in enumerate(phrases):\n",
    "    embedding = infer(x)\n",
    "    nodes.append(embedding)\n",
    "    \n",
    "nodes = np.array(nodes)  \n",
    "\n",
    "all_ids = list(data['actorID']) + list(data['objectID'])\n",
    "all_ids = set(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T15:06:20.266710Z",
     "iopub.status.busy": "2025-12-17T15:06:20.266506Z",
     "iopub.status.idle": "2025-12-17T15:06:43.950079Z",
     "shell.execute_reply": "2025-12-17T15:06:43.949292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 67383, True Negatives: 1126666, False Positives: 6969, False Negatives: 790\n",
      "Precision: 0.91, Recall: 0.99, Fscore: 0.95\n"
     ]
    }
   ],
   "source": [
    "graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "for m_n in range(10):\n",
    "  # model.load_state_dict(torch.load(f'trained_weights/trace/lword2vec_gnn_trace{m_n}_E3.pth'))\n",
    "  model.load_state_dict(torch.load(f'lword2vec_gnn_trace{m_n}_E3.pth'))\n",
    "  loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000)    \n",
    "  for subg in loader:\n",
    "      model.eval()\n",
    "      out = model(subg.x, subg.edge_index)\n",
    "\n",
    "      sorted, indices = out.sort(dim=1,descending=True)\n",
    "      conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "      conf = (conf - conf.min()) / conf.max()\n",
    "    \n",
    "      pred = indices[:,0]\n",
    "      cond = (pred == subg.y)# & (conf >= 0.3)\n",
    "      subg.n_id = subg.n_id.to(device)\n",
    "      flag[subg.n_id[cond]] = torch.logical_and(flag[subg.n_id[cond]], torch.tensor([False]*len(flag[subg.n_id[cond]]), dtype=torch.bool).to(device))\n",
    "\n",
    "index = utils.mask_to_index(flag).tolist()\n",
    "ids = set([mapp[x] for x in index])\n",
    "alerts = helper(set(ids),set(all_ids),GT_mal,edges,mapp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T15:06:43.953656Z",
     "iopub.status.busy": "2025-12-17T15:06:43.953394Z",
     "iopub.status.idle": "2025-12-17T15:06:43.960967Z",
     "shell.execute_reply": "2025-12-17T15:06:43.960493Z"
    }
   },
   "outputs": [],
   "source": [
    "def traverse(ids, mapping, edges, hops, visited=None):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "\n",
    "    neighbors = set()\n",
    "    for src, dst in zip(edges[0], edges[1]):\n",
    "        src_mapped, dst_mapped = mapping[src], mapping[dst]\n",
    "\n",
    "        if (src_mapped in ids and dst_mapped not in visited) or \\\n",
    "           (dst_mapped in ids and src_mapped not in visited):\n",
    "            neighbors.add(src_mapped)\n",
    "            neighbors.add(dst_mapped)\n",
    "\n",
    "        visited.add(src_mapped)\n",
    "        visited.add(dst_mapped)\n",
    "\n",
    "    neighbors.difference_update(ids) \n",
    "    return ids.union(traverse(neighbors, mapping, edges, hops - 1, visited))\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def find_connected_alerts(start_alert, mapping, edges, depth, remaining_alerts):\n",
    "    connected_path = traverse({start_alert}, mapping, edges, depth)\n",
    "    return connected_path.intersection(remaining_alerts)\n",
    "\n",
    "def generate_incident_graphs(alerts, edges, mapping, depth):\n",
    "    incident_graphs = []\n",
    "    remaining_alerts = set(alerts)\n",
    "\n",
    "    while remaining_alerts:\n",
    "        alert = remaining_alerts.pop()\n",
    "        connected_alerts = find_connected_alerts(alert, mapping, edges, depth, remaining_alerts)\n",
    "\n",
    "        if len(connected_alerts) > 1:\n",
    "            incident_graphs.append(connected_alerts)\n",
    "            remaining_alerts -= connected_alerts\n",
    "\n",
    "    return incident_graphs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "flash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
