{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on DARPA E3 Cadets Dataset: \n",
    "\n",
    "This notebook is specifically designed for the evaluation of Flash on the DARPA E3 Cadets dataset. Notably, the Cadets dataset is characterized as a node-level dataset. In our analysis, Flash is configured to operate in a node-level setting to aptly assess this dataset. A key aspect to note is that the Cadets dataset lacks certain essential node attributes for specific node types. This limitation means that Flash cannot be operated in a decoupled mode with offline GNN embeddings for this dataset. Consequently, we employ an online GNN coupled with word2vec semantic embeddings to achieve effective evaluation results for this dataset.\n",
    "\n",
    "## Dataset Access: \n",
    "- Access the Cadets dataset via the following link: [Cadets Dataset](https://drive.google.com/drive/folders/1QlbUFWAGq3Hpl8wVdzOdIoZLFxkII4EK).\n",
    "- The dataset files will be downloaded automatically by the script.\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- The script is designed to automatically parse the downloaded data files.\n",
    "- Execute all cells within this notebook to obtain the evaluation results.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- The notebook is configured to use pre-trained model weights by default.\n",
    "- It also provides the option to set parameters for independently training Graph Neural Networks (GNNs) and word2vec models.\n",
    "- These newly trained models can then be utilized for a comprehensive evaluation of the dataset.\n",
    "\n",
    "Adhere to these steps for a detailed and effective analysis of the Cadets dataset using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:32.679971Z",
     "iopub.status.busy": "2025-12-23T18:45:32.679728Z",
     "iopub.status.idle": "2025-12-23T18:45:35.922383Z",
     "shell.execute_reply": "2025-12-23T18:45:35.921515Z"
    },
    "id": "F1op-CbyLuN4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "# import orjson as json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "import csv\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "import subprocess\n",
    "gpu_mem = {int(x.split(',')[0]): int(x.split(',')[1]) for x in subprocess.check_output(\n",
    "    [\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"], \n",
    "    encoding='utf-8').strip().split('\\n')}\n",
    "best_gpu = max(gpu_mem.items(), key=lambda x: x[1])[0]\n",
    "device = torch.device(f'cuda:{best_gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.956303Z",
     "iopub.status.busy": "2025-12-23T18:45:35.954964Z",
     "iopub.status.idle": "2025-12-23T18:45:35.960342Z",
     "shell.execute_reply": "2025-12-23T18:45:35.959508Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# urls = [\"https://drive.google.com/file/d/1AcWrYiBmgAqp7DizclKJYYJJBQbnDMfb/view?usp=drive_link\",\n",
    "#       \"https://drive.google.com/file/d/1EycO23tEvZVnN3VxOHZ7gdbSCwqEZTI1/view?usp=drive_link\"]\n",
    "# for url in urls:\n",
    "#     gdown.download(url, quiet=False, use_cookies=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.961985Z",
     "iopub.status.busy": "2025-12-23T18:45:35.961627Z",
     "iopub.status.idle": "2025-12-23T18:45:35.964283Z",
     "shell.execute_reply": "2025-12-23T18:45:35.963774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.966008Z",
     "iopub.status.busy": "2025-12-23T18:45:35.965558Z",
     "iopub.status.idle": "2025-12-23T18:45:35.968312Z",
     "shell.execute_reply": "2025-12-23T18:45:35.967820Z"
    },
    "id": "nM7KaeCbA_mQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.969861Z",
     "iopub.status.busy": "2025-12-23T18:45:35.969696Z",
     "iopub.status.idle": "2025-12-23T18:45:35.983942Z",
     "shell.execute_reply": "2025-12-23T18:45:35.983267Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_uuid(line):\n",
    "    pattern_uuid = re.compile(r'uuid\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_uuid.findall(line)\n",
    "\n",
    "def extract_subject_type(line):\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_type.findall(line)\n",
    "\n",
    "def show(file_path):\n",
    "    print(f\"Processing {file_path}\")\n",
    "\n",
    "def extract_edge_info(line):\n",
    "    pattern_src = re.compile(r'subject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst1 = re.compile(r'predicateObject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst2 = re.compile(r'predicateObject2\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    pattern_time = re.compile(r'timestampNanos\\\":(.*?),')\n",
    "\n",
    "    edge_type = extract_subject_type(line)[0]\n",
    "    timestamp = pattern_time.findall(line)[0]\n",
    "    src_id = pattern_src.findall(line)\n",
    "\n",
    "    if len(src_id) == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    src_id = src_id[0]\n",
    "    dst_id1 = pattern_dst1.findall(line)\n",
    "    dst_id2 = pattern_dst2.findall(line)\n",
    "\n",
    "    if len(dst_id1) > 0 and dst_id1[0] != 'null':\n",
    "        dst_id1 = dst_id1[0]\n",
    "    else:\n",
    "        dst_id1 = None\n",
    "\n",
    "    if len(dst_id2) > 0 and dst_id2[0] != 'null':\n",
    "        dst_id2 = dst_id2[0]\n",
    "    else:\n",
    "        dst_id2 = None\n",
    "\n",
    "    return src_id, edge_type, timestamp, dst_id1, dst_id2\n",
    "\n",
    "def process_data(file_path):\n",
    "    id_nodetype_map = {}\n",
    "    notice_num = 1000000\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f:\n",
    "            show(now_path)\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line or 'com.bbn.tc.schema.avro.cdm18.Host' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.TimeMarker' in line or 'com.bbn.tc.schema.avro.cdm18.StartMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.UnitDependency' in line or 'com.bbn.tc.schema.avro.cdm18.EndMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                uuid = extract_uuid(line)[0]\n",
    "                subject_type = extract_subject_type(line)\n",
    "\n",
    "                if len(subject_type) < 1:\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.MemoryObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'MemoryObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.NetFlowObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'NetFlowObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.UnnamedPipeObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'UnnamedPipeObject'\n",
    "                        continue\n",
    "\n",
    "                id_nodetype_map[uuid] = subject_type[0]\n",
    "\n",
    "    return id_nodetype_map\n",
    "\n",
    "def process_edges(file_path, id_nodetype_map):\n",
    "    notice_num = 1000000\n",
    "    not_in_cnt = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f, open(now_path+'.txt', 'w') as fw:\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line:\n",
    "                    src_id, edge_type, timestamp, dst_id1, dst_id2 = extract_edge_info(line)\n",
    "\n",
    "                    if src_id is None or src_id not in id_nodetype_map:\n",
    "                        not_in_cnt += 1\n",
    "                        continue\n",
    "\n",
    "                    src_type = id_nodetype_map[src_id]\n",
    "\n",
    "                    if dst_id1 is not None and dst_id1 in id_nodetype_map:\n",
    "                        dst_type1 = id_nodetype_map[dst_id1]\n",
    "                        this_edge1 = f\"{src_id}\\t{src_type}\\t{dst_id1}\\t{dst_type1}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge1)\n",
    "\n",
    "                    if dst_id2 is not None and dst_id2 in id_nodetype_map:\n",
    "                        dst_type2 = id_nodetype_map[dst_id2]\n",
    "                        this_edge2 = f\"{src_id}\\t{src_type}\\t{dst_id2}\\t{dst_type2}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge2)\n",
    "\n",
    "def run_data_processing():\n",
    "    os.system('tar -zxvf ta1-cadets-e3-official.json.tar.gz')\n",
    "    os.system('tar -zxvf ta1-cadets-e3-official-2.json.tar.gz')\n",
    "\n",
    "    path_list = ['ta1-cadets-e3-official.json', 'ta1-cadets-e3-official-2.json']\n",
    "\n",
    "    for path in path_list:\n",
    "        id_nodetype_map = process_data(path)\n",
    "        process_edges(path, id_nodetype_map)\n",
    "\n",
    "    os.system('cp ta1-cadets-e3-official.json.1.txt cadets_train.txt')\n",
    "    os.system('cp ta1-cadets-e3-official-2.json.txt cadets_test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.985438Z",
     "iopub.status.busy": "2025-12-23T18:45:35.985264Z",
     "iopub.status.idle": "2025-12-23T18:45:35.987787Z",
     "shell.execute_reply": "2025-12-23T18:45:35.987285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run_data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:35.989306Z",
     "iopub.status.busy": "2025-12-23T18:45:35.989142Z",
     "iopub.status.idle": "2025-12-23T18:45:35.999991Z",
     "shell.execute_reply": "2025-12-23T18:45:35.999407Z"
    },
    "id": "BfjmrhfUr3pK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_node_properties(nodes, node_id, properties):\n",
    "    if node_id not in nodes:\n",
    "        nodes[node_id] = []\n",
    "    nodes[node_id].extend(properties)\n",
    "\n",
    "def update_edge_index(edges, edge_index, index):\n",
    "    for src_id, dst_id in edges:\n",
    "        src = index[src_id]\n",
    "        dst = index[dst_id]\n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)\n",
    "\n",
    "def prepare_graph(df):\n",
    "    nodes, labels, edges = {}, {}, []\n",
    "    dummies = {'SUBJECT_PROCESS': 0, 'FILE_OBJECT_FILE': 1, 'FILE_OBJECT_UNIX_SOCKET': 2, \n",
    "               'UnnamedPipeObject': 3, 'NetFlowObject': 4, 'FILE_OBJECT_DIR': 5}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        action = row[\"action\"]\n",
    "        properties = [row['exec'], action] + ([row['path']] if row['path'] else [])\n",
    "        \n",
    "        actor_id = row[\"actorID\"]\n",
    "        add_node_properties(nodes, actor_id, properties)\n",
    "        labels[actor_id] = dummies[row['actor_type']]\n",
    "\n",
    "        object_id = row[\"objectID\"]\n",
    "        add_node_properties(nodes, object_id, properties)\n",
    "        labels[object_id] = dummies[row['object']]\n",
    "\n",
    "        edges.append((actor_id, object_id))\n",
    "\n",
    "    features, feat_labels, edge_index, index_map = [], [], [[], []], {}\n",
    "    for node_id, props in nodes.items():\n",
    "        features.append(props)\n",
    "        feat_labels.append(labels[node_id])\n",
    "        index_map[node_id] = len(features) - 1\n",
    "\n",
    "    update_edge_index(edges, edge_index, index_map)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(index_map.keys()), index_map\n",
    "\n",
    "dummies = {'SUBJECT_PROCESS': 0, 'FILE_OBJECT_FILE': 1, 'FILE_OBJECT_UNIX_SOCKET': 2, \n",
    "               'UnnamedPipeObject': 3, 'NetFlowObject': 4, 'FILE_OBJECT_DIR': 5}\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def add_csv_edges_efficient(original_features, original_labels, original_edge_index, original_mapp, original_mapidx, csv_path, thres=450): \n",
    "    csv_edges = []\n",
    "    csv_nodes = set()\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            src_id, dst_id = row[0], row[1]\n",
    "            csv_edges.append((src_id, dst_id))\n",
    "            csv_nodes.add(src_id)\n",
    "            csv_nodes.add(dst_id)\n",
    "    \n",
    "    extended_features = original_features.copy()\n",
    "    extended_labels = original_labels.copy()\n",
    "    extended_edge_index = [original_edge_index[0].copy(), original_edge_index[1].copy()]\n",
    "    extended_mapp = original_mapp.copy()\n",
    "    extended_mapidx = original_mapidx.copy()\n",
    "\n",
    "    degrees = defaultdict(int)\n",
    "    for src_idx in extended_edge_index[0]:\n",
    "        degrees[src_idx] += 1\n",
    "    for dst_idx in extended_edge_index[1]:\n",
    "        degrees[dst_idx] += 1\n",
    "    \n",
    "    all_degrees = list(degrees.values())\n",
    "    all_degrees.sort(reverse=True)\n",
    "    print(all_degrees[:3000])\n",
    "\n",
    "    count1, count2, count3 = 0, 0, 0\n",
    "    for src_id, dst_id in csv_edges:\n",
    "        if src_id in extended_mapidx and dst_id in extended_mapidx:\n",
    "            src_idx = extended_mapidx[src_id]\n",
    "            dst_idx = extended_mapidx[dst_id]\n",
    "            if degrees[src_idx] <= thres and degrees[dst_idx] <= thres:\n",
    "                extended_edge_index[0].append(src_idx)\n",
    "                extended_edge_index[1].append(dst_idx)\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1\n",
    "        else:\n",
    "            count3 += 1\n",
    "    print(f'Sucessfully add edges: {count1}\\tPrune edges: {count2}\\tFail to add edges: {count3}')\n",
    "    \n",
    "    return extended_features, extended_labels, extended_edge_index, extended_mapp, extended_mapidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.001641Z",
     "iopub.status.busy": "2025-12-23T18:45:36.001477Z",
     "iopub.status.idle": "2025-12-23T18:45:36.005939Z",
     "shell.execute_reply": "2025-12-23T18:45:36.005414Z"
    },
    "id": "fmXWs1dKIzD8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 4, normalize=True)\n",
    "        self.conv2 = SAGEConv(4, out_channel, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.007663Z",
     "iopub.status.busy": "2025-12-23T18:45:36.007220Z",
     "iopub.status.idle": "2025-12-23T18:45:36.010734Z",
     "shell.execute_reply": "2025-12-23T18:45:36.010221Z"
    },
    "id": "YBuP_tSq94f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.012191Z",
     "iopub.status.busy": "2025-12-23T18:45:36.012014Z",
     "iopub.status.idle": "2025-12-23T18:45:36.084409Z",
     "shell.execute_reply": "2025-12-23T18:45:36.083474Z"
    },
    "id": "3PCP6SXwZaif"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('word2vec_cadets_E3.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.087450Z",
     "iopub.status.busy": "2025-12-23T18:45:36.087281Z",
     "iopub.status.idle": "2025-12-23T18:45:36.090920Z",
     "shell.execute_reply": "2025-12-23T18:45:36.090392Z"
    },
    "id": "P8oBL8LFaeOf"
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.092359Z",
     "iopub.status.busy": "2025-12-23T18:45:36.092189Z",
     "iopub.status.idle": "2025-12-23T18:45:36.094680Z",
     "shell.execute_reply": "2025-12-23T18:45:36.094193Z"
    },
    "id": "Se7Ei4tAapVj"
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.096073Z",
     "iopub.status.busy": "2025-12-23T18:45:36.095918Z",
     "iopub.status.idle": "2025-12-23T18:45:36.102502Z",
     "shell.execute_reply": "2025-12-23T18:45:36.101971Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_attributes(d,p):\n",
    "    \n",
    "    f = open(p)\n",
    "    data = [json.loads(x) for x in f if \"EVENT\" in x]\n",
    "\n",
    "    info = []\n",
    "    for x in data:\n",
    "        try:\n",
    "            action = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['type']\n",
    "        except:\n",
    "            action = ''\n",
    "        try:\n",
    "            actor = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['subject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            actor = ''\n",
    "        try:\n",
    "            obj = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            obj = ''\n",
    "        try:\n",
    "            timestamp = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['timestampNanos']\n",
    "        except:\n",
    "            timestamp = ''\n",
    "        try:\n",
    "            cmd = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['properties']['map']['exec']\n",
    "        except:\n",
    "            cmd = ''\n",
    "        try:\n",
    "            path = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObjectPath']['string']\n",
    "        except:\n",
    "            path = ''\n",
    "        try:\n",
    "            path2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2Path']['string']\n",
    "        except:\n",
    "            path2 = ''\n",
    "        try:\n",
    "            obj2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "            info.append({'actorID':actor,'objectID':obj2,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path2})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        info.append({'actorID':actor,'objectID':obj,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path})\n",
    "\n",
    "    rdf = pd.DataFrame.from_records(info).astype(str)\n",
    "    d = d.astype(str)\n",
    "\n",
    "    return d.merge(rdf,how='inner',on=['actorID','objectID','action','timestamp']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:45:36.103948Z",
     "iopub.status.busy": "2025-12-23T18:45:36.103782Z",
     "iopub.status.idle": "2025-12-23T18:51:01.693529Z",
     "shell.execute_reply": "2025-12-23T18:51:01.692482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[484562, 166868, 86735, 80498, 80097, 79600, 75947, 65805, 53932, 40934, 35035, 34875, 27892, 26597, 25340, 22022, 20011, 19218, 17790, 16506, 16498, 16009, 15512, 15309, 12798, 12556, 12536, 12366, 11537, 11501, 9901, 9786, 9621, 9174, 8952, 8012, 8004, 7970, 7196, 7114, 7113, 6620, 6202, 6163, 6067, 6004, 5784, 5531, 5506, 5368, 4682, 4315, 4038, 4003, 4002, 3806, 3715, 3428, 3389, 3314, 3237, 3015, 2856, 2761, 2759, 2611, 2593, 2481, 2473, 2395, 2106, 2083, 2076, 2051, 2033, 2028, 2018, 2002, 2001, 2001, 2001, 1980, 1958, 1880, 1862, 1800, 1760, 1734, 1731, 1643, 1601, 1600, 1596, 1568, 1563, 1548, 1544, 1533, 1527, 1525, 1505, 1503, 1503, 1501, 1495, 1494, 1484, 1478, 1441, 1441, 1426, 1421, 1408, 1372, 1364, 1359, 1278, 1272, 1241, 1224, 1212, 1173, 1168, 1154, 1094, 1091, 1076, 1050, 1037, 1022, 1016, 1015, 1008, 984, 969, 968, 947, 929, 925, 919, 918, 910, 898, 898, 898, 897, 890, 880, 868, 866, 866, 865, 862, 854, 845, 833, 832, 816, 815, 815, 812, 811, 811, 811, 810, 810, 810, 809, 809, 808, 808, 808, 808, 808, 807, 807, 807, 807, 806, 805, 805, 801, 793, 785, 783, 781, 776, 772, 765, 750, 733, 695, 689, 681, 675, 675, 664, 658, 653, 653, 652, 646, 636, 636, 634, 632, 627, 626, 610, 609, 608, 606, 601, 599, 599, 596, 594, 592, 591, 572, 568, 566, 563, 554, 547, 547, 541, 531, 521, 518, 508, 503, 501, 501, 499, 499, 498, 498, 497, 497, 496, 495, 493, 490, 490, 490, 490, 486, 483, 483, 483, 482, 476, 469, 463, 461, 460, 457, 455, 455, 453, 452, 451, 447, 442, 440, 440, 440, 437, 435, 432, 427, 427, 420, 420, 418, 415, 414, 412, 412, 406, 405, 405, 404, 403, 403, 403, 402, 400, 400, 399, 398, 398, 398, 397, 395, 395, 394, 393, 391, 391, 391, 390, 390, 387, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 386, 385, 384, 383, 383, 381, 380, 379, 379, 378, 378, 377, 377, 377, 376, 375, 375, 375, 375, 371, 370, 370, 369, 367, 367, 366, 365, 364, 363, 363, 362, 361, 360, 360, 360, 360, 359, 359, 359, 358, 358, 358, 358, 357, 357, 357, 353, 353, 353, 352, 352, 352, 351, 351, 350, 350, 350, 349, 348, 348, 348, 346, 346, 345, 345, 344, 344, 343, 342, 342, 342, 342, 341, 341, 341, 341, 339, 339, 338, 338, 338, 338, 337, 337, 334, 334, 331, 330, 329, 325, 325, 324, 323, 323, 323, 322, 319, 318, 315, 312, 311, 310, 309, 309, 309, 308, 306, 306, 305, 305, 305, 305, 304, 303, 303, 302, 301, 301, 301, 300, 299, 299, 299, 299, 298, 298, 297, 297, 296, 296, 296, 296, 296, 295, 295, 294, 294, 294, 294, 293, 293, 292, 292, 292, 292, 290, 289, 289, 289, 289, 288, 288, 288, 288, 287, 286, 286, 286, 286, 285, 285, 285, 285, 284, 284, 284, 284, 284, 284, 284, 283, 283, 283, 283, 282, 281, 281, 281, 281, 281, 281, 281, 280, 280, 280, 280, 280, 279, 279, 279, 279, 279, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 277, 277, 277, 276, 276, 276, 276, 275, 275, 275, 275, 275, 275, 275, 274, 274, 274, 273, 273, 273, 273, 273, 273, 273, 272, 272, 272, 272, 272, 271, 271, 271, 271, 271, 270, 270, 270, 270, 269, 269, 268, 267, 267, 266, 266, 266, 265, 265, 265, 260, 260, 260, 260, 259, 258, 258, 258, 258, 257, 257, 257, 257, 257, 257, 256, 256, 256, 256, 256, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 254, 253, 253, 253, 253, 253, 252, 252, 252, 252, 251, 250, 250, 250, 250, 250, 249, 249, 249, 249, 249, 248, 248, 248, 248, 248, 247, 247, 245, 244, 244, 243, 243, 243, 243, 243, 242, 242, 240, 239, 239, 239, 238, 237, 237, 237, 237, 237, 236, 236, 235, 234, 234, 233, 232, 231, 231, 231, 230, 230, 230, 230, 229, 229, 229, 228, 228, 228, 228, 227, 227, 227, 227, 227, 226, 226, 226, 226, 225, 225, 225, 225, 224, 224, 224, 224, 224, 223, 223, 223, 223, 223, 223, 223, 223, 222, 222, 222, 222, 222, 222, 221, 221, 221, 221, 220, 220, 220, 220, 220, 219, 219, 219, 219, 218, 218, 218, 217, 216, 216, 216, 216, 216, 216, 215, 215, 215, 215, 215, 214, 214, 214, 214, 214, 213, 213, 213, 213, 212, 212, 212, 212, 212, 212, 212, 212, 212, 212, 211, 211, 211, 211, 211, 211, 211, 211, 210, 210, 210, 210, 209, 209, 209, 209, 209, 208, 208, 208, 208, 208, 208, 208, 208, 207, 207, 207, 207, 207, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 197, 197, 197, 197, 197, 197, 197, 197, 196, 196, 196, 196, 196, 196, 195, 194, 193, 193, 191, 190, 190, 190, 189, 188, 187, 187, 187, 187, 187, 187, 186, 186, 186, 186, 185, 185, 185, 185, 185, 185, 185, 184, 184, 184, 184, 184, 184, 184, 183, 183, 183, 183, 182, 182, 182, 182, 182, 182, 182, 182, 182, 181, 181, 181, 181, 181, 181, 181, 180, 180, 180, 180, 180, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 178, 178, 178, 178, 178, 178, 178, 178, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 175, 175, 175, 175, 175, 175, 175, 175, 175, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 172, 172, 172, 172, 172, 172, 172, 172, 172, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 170, 170, 170, 170, 170, 170, 170, 170, 170, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 167, 167, 167, 167, 167, 167, 167, 167, 166, 166, 166, 166, 166, 165, 165, 165, 165, 164, 164, 164, 163, 163, 163, 163, 163, 162, 162, 162, 162, 161, 161, 161, 160, 160, 160, 159, 159, 158, 158, 158, 158, 158, 158, 158, 157, 157, 157, 156, 156, 156, 156, 156, 156, 156, 156, 155, 155, 155, 155, 155, 154, 154, 154, 154, 154, 154, 154, 154, 153, 153, 153, 153, 153, 153, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 151, 151, 151, 151, 151, 151, 151, 151, 151, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115]\n",
      "Sucessfully add edges: 375\tPrune edges: 1427\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "if Train:\n",
    "    f = open(\"../cadets_train.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df = df.dropna()\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = add_attributes(df,\"../ta1-cadets-e3-official.json.1\")\n",
    "    phrases,labels,edges,mapp,mapidx = prepare_graph(df)\n",
    "    csv_path = \"../../flash-add-edge/cadets_train.csv\"\n",
    "    phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "        phrases, labels, edges, mapp, mapidx, csv_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:01.695854Z",
     "iopub.status.busy": "2025-12-23T18:51:01.695509Z",
     "iopub.status.idle": "2025-12-23T18:51:02.008123Z",
     "shell.execute_reply": "2025-12-23T18:51:02.007140Z"
    },
    "id": "p3TAi69zI1bO"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# model = GCN(30,6).to(device)\n",
    "model = GCN(4,6).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:02.012482Z",
     "iopub.status.busy": "2025-12-23T18:51:02.012053Z",
     "iopub.status.idle": "2025-12-23T18:51:02.016254Z",
     "shell.execute_reply": "2025-12-23T18:51:02.015373Z"
    },
    "id": "3RDmGME5iPb5"
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:02.018308Z",
     "iopub.status.busy": "2025-12-23T18:51:02.017861Z",
     "iopub.status.idle": "2025-12-23T18:51:02.021548Z",
     "shell.execute_reply": "2025-12-23T18:51:02.020819Z"
    }
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=10, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:02.023887Z",
     "iopub.status.busy": "2025-12-23T18:51:02.023123Z",
     "iopub.status.idle": "2025-12-23T18:51:02.657008Z",
     "shell.execute_reply": "2025-12-23T18:51:02.656142Z"
    },
    "id": "Vn_pMyt5Jd-6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000):\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "\n",
    "def infer(document):\n",
    "    word_embeddings = [w2vmodel.wv[word] for word in document if word in w2vmodel.wv]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(4)\n",
    "    \n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    mean_embedding = np.mean(output_embedding, axis=0)\n",
    "    \n",
    "    return mean_embedding\n",
    "\n",
    "# encoder = PositionalEncoder(30)\n",
    "encoder = PositionalEncoder(4)\n",
    "# w2vmodel = Word2Vec.load(\"trained_weights/cadets/word2vec_cadets_E3.model\")\n",
    "w2vmodel = Word2Vec.load(\"../word2vec_cadets_E3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:02.660638Z",
     "iopub.status.busy": "2025-12-23T18:51:02.660453Z",
     "iopub.status.idle": "2025-12-23T18:51:42.516253Z",
     "shell.execute_reply": "2025-12-23T18:51:42.515288Z"
    },
    "executionInfo": {
     "elapsed": 126525,
     "status": "ok",
     "timestamp": 1673576225797,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "4fda4903-b842-4bfb-8316-c8a82bd4cee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7157109024642074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 63959 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.749706493538736\n",
      "Model# 1. 23568 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7980547039102552\n",
      "Model# 2. 23525 nodes still misclassified \n",
      "\n",
      "1.7898650894002883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 3. 23486 nodes still misclassified \n",
      "\n",
      "1.7750847627628725\n",
      "Model# 4. 19483 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7831676224935828\n",
      "Model# 5. 18873 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7607884162535874\n",
      "Model# 6. 17940 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7571397129375665\n",
      "Model# 7. 9864 nodes still misclassified \n",
      "\n",
      "1.7715551816440653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 8. 9736 nodes still misclassified \n",
      "\n",
      "1.7559255280255683\n",
      "Model# 9. 9687 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.757235201062021\n",
      "Model# 10. 9671 nodes still misclassified \n",
      "\n",
      "1.7432824892189618\n",
      "Model# 11. 9636 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7488973289666307\n",
      "Model# 12. 9569 nodes still misclassified \n",
      "\n",
      "1.7364291804924892\n",
      "Model# 13. 9343 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320710079682455\n",
      "Model# 14. 7062 nodes still misclassified \n",
      "\n",
      "1.7317774552726368\n",
      "Model# 15. 6806 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7312906700969968\n",
      "Model# 16. 6788 nodes still misclassified \n",
      "\n",
      "1.7254704291776972\n",
      "Model# 17. 6740 nodes still misclassified \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7046938805622587\n",
      "Model# 18. 6547 nodes still misclassified \n",
      "\n",
      "1.7153665789469736\n",
      "Model# 19. 6542 nodes still misclassified \n",
      "\n",
      "1.7217129924471537\n",
      "Model# 20. 6542 nodes still misclassified \n",
      "\n",
      "1.716755916313526\n",
      "Model# 21. 6542 nodes still misclassified \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "if Train:\n",
    "    l = np.array(labels)\n",
    "    \n",
    "    ngram_class_weights = [\n",
    "        0.7339,  \n",
    "        1.0213,   \n",
    "        1.1339,   \n",
    "        0.5000,   \n",
    "        1.5000,   \n",
    "        0.8151  \n",
    "    ]\n",
    "    class_weights = torch.tensor(ngram_class_weights,dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for m_n in range(22):\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      total_loss = 0\n",
    "      for subg in loader:\n",
    "          model.train()\n",
    "          optimizer.zero_grad() \n",
    "          out = model(subg.x, subg.edge_index) \n",
    "          loss = criterion(out, subg.y) \n",
    "          loss.backward() \n",
    "          optimizer.step()      \n",
    "          total_loss += loss.item() * subg.batch_size\n",
    "      losses.append(total_loss / mask.sum().item())\n",
    "      print(total_loss / mask.sum().item())\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      for subg in loader:\n",
    "          model.eval()\n",
    "          out = model(subg.x, subg.edge_index)\n",
    "\n",
    "          sorted, indices = out.sort(dim=1,descending=True)\n",
    "          conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "          conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "          pred = indices[:,0]\n",
    "          cond = (pred == subg.y) | (conf >= 0.9)\n",
    "          subg.n_id = subg.n_id.to(device)\n",
    "          mask[subg.n_id[cond]] = False\n",
    "\n",
    "      torch.save(model.state_dict(), f'lword2vec_gnn_cadets{m_n}_E3.pth')\n",
    "      print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:42.518951Z",
     "iopub.status.busy": "2025-12-23T18:51:42.518516Z",
     "iopub.status.idle": "2025-12-23T18:51:42.522353Z",
     "shell.execute_reply": "2025-12-23T18:51:42.521909Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "# plt.title(\"GNN Training Loss Curve on Cadets\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.xticks(range(0, 22, 2))  # 0-19epoch\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:42.523886Z",
     "iopub.status.busy": "2025-12-23T18:51:42.523658Z",
     "iopub.status.idle": "2025-12-23T18:51:42.532004Z",
     "shell.execute_reply": "2025-12-23T18:51:42.531506Z"
    },
    "id": "vgqyu7E5qPet"
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def Get_Adjacent(ids, mapp, edges, hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    \n",
    "    neighbors = set()\n",
    "    for edge in zip(edges[0], edges[1]):\n",
    "        if any(mapp[node] in ids for node in edge):\n",
    "            neighbors.update(mapp[node] for node in edge)\n",
    "\n",
    "    if hops > 1:\n",
    "        neighbors = neighbors.union(Get_Adjacent(neighbors, mapp, edges, hops - 1))\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def calculate_metrics(TP, FP, FN, TN):\n",
    "    FPR = FP / (FP + TN) if FP + TN > 0 else 0\n",
    "    TPR = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    prec = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    rec = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    fscore = (2 * prec * rec) / (prec + rec) if prec + rec > 0 else 0\n",
    "\n",
    "    return prec, rec, fscore, FPR, TPR\n",
    "\n",
    "def helper(MP, all_pids, GP, edges, mapp):\n",
    "    TP = MP.intersection(GP)\n",
    "    FP = MP - GP\n",
    "    FN = GP - MP\n",
    "    TN = all_pids - (GP | MP)\n",
    "\n",
    "    two_hop_gp = Get_Adjacent(GP, mapp, edges, 2)\n",
    "    two_hop_tp = Get_Adjacent(TP, mapp, edges, 2)\n",
    "    FPL = FP - two_hop_gp\n",
    "    TPL = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "\n",
    "    TP, FP, FN, TN = len(TPL), len(FPL), len(FN), len(TN)\n",
    "\n",
    "    prec, rec, fscore, FPR, TPR = calculate_metrics(TP, FP, FN, TN)\n",
    "    print(f\"True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN}\")\n",
    "    print(f\"Precision: {round(prec, 2)}, Recall: {round(rec, 2)}, Fscore: {round(fscore, 2)}\")\n",
    "    \n",
    "    return TPL, FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:51:42.533640Z",
     "iopub.status.busy": "2025-12-23T18:51:42.533278Z",
     "iopub.status.idle": "2025-12-23T18:52:03.778877Z",
     "shell.execute_reply": "2025-12-23T18:52:03.777831Z"
    },
    "id": "OZFrSLVZ29qU"
   },
   "outputs": [],
   "source": [
    "f = open(\"../cadets_test.txt\")\n",
    "data = f.read().split('\\n')\n",
    "data = [line.split('\\t') for line in data]\n",
    "df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "df = df.dropna()\n",
    "df.sort_values(by='timestamp', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:52:03.782967Z",
     "iopub.status.busy": "2025-12-23T18:52:03.782752Z",
     "iopub.status.idle": "2025-12-23T18:56:20.168269Z",
     "shell.execute_reply": "2025-12-23T18:56:20.167008Z"
    }
   },
   "outputs": [],
   "source": [
    "df = add_attributes(df,\"../ta1-cadets-e3-official-2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:56:20.170626Z",
     "iopub.status.busy": "2025-12-23T18:56:20.170431Z",
     "iopub.status.idle": "2025-12-23T18:58:37.176127Z",
     "shell.execute_reply": "2025-12-23T18:58:37.174889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[428308, 189402, 80187, 73509, 73018, 68393, 65941, 57255, 56958, 46775, 44153, 33784, 32798, 24986, 24408, 22444, 22073, 19477, 19188, 18747, 18545, 17688, 16774, 16723, 16667, 15720, 14944, 14282, 14213, 12877, 11311, 11084, 11010, 10002, 9983, 9255, 8615, 8574, 8430, 7087, 7079, 6514, 6220, 5925, 5603, 5492, 5412, 5306, 5226, 5185, 4903, 4816, 4348, 4073, 4044, 3771, 3590, 3576, 3539, 3536, 3359, 3350, 3278, 2997, 2966, 2668, 2660, 2657, 2599, 2597, 2538, 2516, 2513, 2507, 2438, 2432, 2431, 2426, 2423, 2423, 2421, 2419, 2419, 2403, 2321, 2307, 2305, 2250, 2145, 2062, 1892, 1845, 1840, 1811, 1809, 1802, 1799, 1785, 1773, 1769, 1768, 1768, 1748, 1748, 1740, 1739, 1723, 1670, 1656, 1646, 1622, 1593, 1590, 1567, 1561, 1555, 1549, 1537, 1523, 1496, 1494, 1487, 1465, 1462, 1460, 1452, 1443, 1442, 1436, 1434, 1413, 1406, 1386, 1380, 1371, 1362, 1353, 1351, 1336, 1334, 1323, 1321, 1319, 1316, 1300, 1300, 1297, 1292, 1289, 1281, 1281, 1265, 1256, 1255, 1253, 1250, 1245, 1234, 1222, 1220, 1212, 1193, 1186, 1170, 1164, 1143, 1114, 1106, 1099, 1088, 1080, 1068, 1026, 1022, 1021, 1015, 1006, 1000, 968, 966, 960, 958, 956, 950, 933, 926, 918, 915, 891, 872, 855, 852, 851, 846, 844, 843, 839, 823, 817, 814, 813, 812, 812, 812, 812, 811, 810, 810, 809, 809, 808, 808, 808, 808, 807, 807, 806, 806, 804, 795, 795, 793, 784, 779, 770, 750, 746, 744, 730, 725, 725, 720, 720, 720, 717, 696, 691, 690, 690, 685, 673, 671, 662, 661, 648, 648, 647, 644, 643, 637, 619, 611, 608, 608, 605, 602, 601, 600, 599, 595, 592, 588, 587, 586, 584, 583, 583, 583, 582, 580, 579, 573, 573, 571, 569, 564, 561, 554, 552, 550, 540, 537, 529, 526, 524, 521, 520, 519, 515, 510, 508, 508, 505, 505, 504, 504, 501, 500, 498, 497, 496, 495, 494, 491, 490, 490, 490, 490, 489, 489, 489, 488, 487, 486, 486, 486, 483, 476, 476, 470, 470, 467, 462, 459, 459, 455, 454, 454, 453, 449, 444, 443, 441, 436, 435, 435, 431, 430, 425, 423, 422, 421, 420, 418, 415, 414, 412, 411, 410, 409, 409, 409, 409, 407, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 403, 403, 400, 400, 398, 398, 398, 398, 397, 397, 397, 396, 396, 396, 394, 393, 392, 392, 392, 392, 392, 391, 390, 389, 389, 388, 388, 388, 387, 387, 385, 384, 383, 383, 382, 382, 382, 382, 381, 381, 379, 379, 376, 374, 373, 373, 373, 373, 372, 371, 370, 369, 369, 369, 368, 367, 366, 365, 365, 365, 365, 364, 364, 363, 363, 362, 362, 362, 361, 361, 361, 360, 360, 358, 358, 357, 357, 357, 356, 356, 356, 356, 356, 355, 355, 355, 355, 355, 354, 353, 353, 353, 352, 352, 351, 351, 350, 349, 349, 347, 346, 346, 346, 345, 345, 344, 342, 342, 340, 340, 338, 338, 337, 336, 335, 335, 335, 334, 333, 333, 333, 333, 332, 332, 332, 331, 331, 331, 330, 329, 329, 329, 328, 328, 328, 327, 327, 327, 327, 327, 327, 326, 325, 325, 325, 325, 325, 325, 325, 324, 324, 324, 324, 324, 324, 323, 323, 323, 322, 322, 322, 322, 321, 321, 321, 321, 321, 320, 320, 319, 319, 319, 318, 318, 318, 318, 318, 317, 317, 317, 317, 317, 316, 316, 315, 315, 315, 314, 314, 314, 312, 312, 312, 310, 310, 309, 309, 309, 308, 308, 308, 307, 307, 307, 307, 307, 306, 306, 306, 306, 305, 305, 305, 305, 304, 304, 304, 304, 303, 303, 303, 303, 302, 302, 302, 302, 302, 302, 302, 301, 301, 301, 300, 300, 299, 299, 299, 299, 299, 299, 298, 298, 298, 298, 297, 297, 297, 297, 297, 296, 296, 296, 296, 296, 296, 295, 295, 295, 294, 294, 294, 294, 294, 294, 294, 293, 293, 293, 293, 293, 293, 293, 292, 292, 292, 292, 292, 291, 291, 291, 291, 290, 290, 290, 290, 290, 290, 289, 289, 289, 289, 289, 288, 288, 288, 288, 288, 287, 287, 287, 286, 285, 285, 285, 285, 285, 284, 284, 284, 284, 283, 283, 283, 282, 282, 282, 282, 282, 281, 281, 281, 280, 280, 280, 280, 280, 280, 279, 279, 279, 279, 279, 279, 279, 278, 278, 278, 278, 278, 278, 275, 275, 275, 275, 275, 275, 275, 272, 272, 272, 271, 271, 270, 269, 268, 267, 267, 267, 267, 265, 265, 265, 264, 263, 263, 263, 263, 263, 263, 262, 262, 262, 262, 261, 261, 260, 260, 260, 259, 259, 259, 259, 259, 258, 258, 257, 257, 257, 257, 257, 257, 256, 256, 256, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 254, 254, 254, 253, 253, 253, 253, 253, 253, 253, 252, 252, 252, 252, 252, 252, 252, 251, 251, 251, 251, 250, 250, 250, 250, 250, 250, 250, 250, 250, 249, 249, 249, 249, 249, 248, 248, 248, 248, 248, 248, 248, 247, 247, 247, 247, 247, 246, 246, 246, 246, 246, 245, 245, 245, 245, 245, 245, 244, 244, 244, 243, 243, 242, 242, 242, 241, 241, 240, 240, 239, 239, 238, 238, 237, 237, 237, 236, 236, 236, 235, 234, 234, 234, 233, 233, 232, 232, 232, 231, 231, 231, 230, 230, 230, 229, 229, 229, 229, 228, 228, 228, 228, 228, 227, 227, 227, 227, 227, 226, 226, 226, 226, 226, 226, 226, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 224, 224, 224, 224, 224, 224, 224, 224, 224, 224, 223, 223, 223, 223, 223, 223, 223, 223, 222, 222, 222, 222, 222, 222, 222, 222, 222, 222, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 219, 219, 219, 219, 219, 219, 219, 219, 219, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 216, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 212, 212, 212, 212, 212, 212, 212, 212, 212, 211, 211, 211, 211, 211, 211, 211, 211, 211, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 208, 208, 208, 208, 208, 208, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 207, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 202, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 197, 197, 197, 197, 197, 197, 197, 197, 197, 196, 196, 195, 195, 195, 194, 194, 194, 193, 192, 192, 191, 191, 191, 191, 191, 190, 190, 190, 189, 189, 189, 189, 188, 188, 188, 188, 188, 188, 188, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 186, 186, 186, 186, 186, 186, 186, 186, 186, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 184, 184, 184, 184, 184, 184, 184, 184, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 182, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 179, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 178, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 176, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 175, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 174, 173, 173, 173, 173, 173, 173, 173, 173, 173, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 171, 171, 171, 171, 171, 171, 171, 170, 170, 170, 170, 170, 170, 169, 169, 169, 169, 169, 169, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 167, 167, 167, 167, 167, 167, 167, 167, 167, 166, 166, 166, 166, 166, 166, 166, 166, 166, 165, 165, 164, 164, 164, 164, 164, 163, 163, 163, 163, 162, 162, 162, 162, 162, 161, 161, 161, 160, 160, 160, 159, 159, 159, 159, 159, 159, 159, 159, 158, 158, 158, 158, 158, 158, 158, 157, 157, 157, 157, 157, 157, 156, 156, 156, 156, 156, 156, 156, 156, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 155, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 152, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115]\n",
      "Sucessfully add edges: 222\tPrune edges: 1256\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data_files/cadets.json\", \"r\") as json_file:\n",
    "    GT_mal = set(json.load(json_file))\n",
    "\n",
    "data = df\n",
    "\n",
    "phrases,labels,edges,mapp,mapidx = prepare_graph(data)\n",
    "\n",
    "csv_path = \"../../flash-add-edge/cadets_test.csv\"\n",
    "phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "    phrases, labels, edges, mapp, mapidx, csv_path\n",
    ")\n",
    "\n",
    "nodes = []\n",
    "for i, x in enumerate(phrases):\n",
    "    embedding = infer(x)\n",
    "    nodes.append(embedding)\n",
    "    \n",
    "nodes = np.array(nodes)\n",
    "\n",
    "all_ids = list(data['actorID']) + list(data['objectID'])\n",
    "all_ids = set(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-23T18:58:37.180366Z",
     "iopub.status.busy": "2025-12-23T18:58:37.180152Z",
     "iopub.status.idle": "2025-12-23T18:58:48.814083Z",
     "shell.execute_reply": "2025-12-23T18:58:48.813582Z"
    },
    "executionInfo": {
     "elapsed": 311255,
     "status": "ok",
     "timestamp": 1673577553815,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "DsLlVS6zpox5",
    "outputId": "e79153e2-2e54-4cbf-c241-1293e0ee2be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 12846, True Negatives: 336694, False Positives: 1393, False Negatives: 12\n",
      "Precision: 0.9, Recall: 1.0, Fscore: 0.95\n"
     ]
    }
   ],
   "source": [
    "graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "for m_n in range(22):\n",
    "  # model.load_state_dict(torch.load(f'trained_weights/cadets/lword2vec_gnn_cadets{m_n}_E3.pth'))\n",
    "  model.load_state_dict(torch.load(f'lword2vec_gnn_cadets{m_n}_E3.pth'))\n",
    "  loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000)    \n",
    "  for subg in loader:\n",
    "      model.eval()\n",
    "      out = model(subg.x, subg.edge_index)\n",
    "\n",
    "      sorted, indices = out.sort(dim=1,descending=True)\n",
    "      conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "      conf = (conf - conf.min()) / conf.max()\n",
    "    \n",
    "      pred = indices[:,0]\n",
    "      cond = (pred == subg.y)\n",
    "      subg.n_id = subg.n_id.to(device)\n",
    "      flag[subg.n_id[cond]] = torch.logical_and(flag[subg.n_id[cond]], torch.tensor([False]*len(flag[subg.n_id[cond]]), dtype=torch.bool).to(device))\n",
    "index = utils.mask_to_index(flag).tolist()\n",
    "ids = set([mapp[x] for x in index])\n",
    "_ = helper(set(ids),set(all_ids),GT_mal,edges,mapp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:58:48.817976Z",
     "iopub.status.busy": "2025-12-23T18:58:48.817786Z",
     "iopub.status.idle": "2025-12-23T18:58:48.825234Z",
     "shell.execute_reply": "2025-12-23T18:58:48.824737Z"
    }
   },
   "outputs": [],
   "source": [
    "def traverse(ids, mapping, edges, hops, visited=None):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "\n",
    "    neighbors = set()\n",
    "    for src, dst in zip(edges[0], edges[1]):\n",
    "        src_mapped, dst_mapped = mapping[src], mapping[dst]\n",
    "\n",
    "        if (src_mapped in ids and dst_mapped not in visited) or \\\n",
    "           (dst_mapped in ids and src_mapped not in visited):\n",
    "            neighbors.add(src_mapped)\n",
    "            neighbors.add(dst_mapped)\n",
    "\n",
    "        visited.add(src_mapped)\n",
    "        visited.add(dst_mapped)\n",
    "\n",
    "    neighbors.difference_update(ids) \n",
    "    return ids.union(traverse(neighbors, mapping, edges, hops - 1, visited))\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def find_connected_alerts(start_alert, mapping, edges, depth, remaining_alerts):\n",
    "    connected_path = traverse({start_alert}, mapping, edges, depth)\n",
    "    return connected_path.intersection(remaining_alerts)\n",
    "\n",
    "def generate_incident_graphs(alerts, edges, mapping, depth):\n",
    "    incident_graphs = []\n",
    "    remaining_alerts = set(alerts)\n",
    "\n",
    "    while remaining_alerts:\n",
    "        alert = remaining_alerts.pop()\n",
    "        connected_alerts = find_connected_alerts(alert, mapping, edges, depth, remaining_alerts)\n",
    "\n",
    "        if len(connected_alerts) > 1:\n",
    "            incident_graphs.append(connected_alerts)\n",
    "            remaining_alerts -= connected_alerts\n",
    "\n",
    "    return incident_graphs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "flash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
