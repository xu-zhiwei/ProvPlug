{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on DARPA E3 Theia Dataset: \n",
    "\n",
    "This notebook is specifically designed for the evaluation of Flash on the DARPA E3 Theia dataset. Notably, the Theia dataset is characterized as a node-level dataset. In our analysis, Flash is configured to operate in a node-level setting to aptly assess this dataset. A key aspect to note is that the Theia dataset lacks certain essential node attributes for specific node types. This limitation means that Flash cannot be operated in a decoupled mode with offline GNN embeddings for this dataset. Consequently, we employ an online GNN coupled with word2vec semantic embeddings to achieve effective evaluation results for this dataset.\n",
    "\n",
    "## Dataset Access: \n",
    "- Access the Theia dataset via the following link: [Theia Dataset](https://drive.google.com/drive/folders/1QlbUFWAGq3Hpl8wVdzOdIoZLFxkII4EK).\n",
    "- The dataset files will be downloaded automatically by the script.\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- The script is designed to automatically parse the downloaded data files.\n",
    "- Execute all cells within this notebook to obtain the evaluation results.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- The notebook is configured to use pre-trained model weights by default.\n",
    "- It also provides the option to set parameters for independently training Graph Neural Networks (GNNs) and word2vec models.\n",
    "- These newly trained models can then be utilized for a comprehensive evaluation of the dataset.\n",
    "\n",
    "Adhere to these steps for a detailed and effective analysis of the Theia dataset using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:55.183736Z",
     "iopub.status.busy": "2025-12-18T11:38:55.183461Z",
     "iopub.status.idle": "2025-12-18T11:38:58.439468Z",
     "shell.execute_reply": "2025-12-18T11:38:58.438836Z"
    },
    "id": "F1op-CbyLuN4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "import csv\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "import subprocess\n",
    "gpu_mem = {int(x.split(',')[0]): int(x.split(',')[1]) for x in subprocess.check_output(\n",
    "    [\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"], \n",
    "    encoding='utf-8').strip().split('\\n')}\n",
    "best_gpu = max(gpu_mem.items(), key=lambda x: x[1])[0]\n",
    "device = torch.device(f'cuda:{best_gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.473622Z",
     "iopub.status.busy": "2025-12-18T11:38:58.472379Z",
     "iopub.status.idle": "2025-12-18T11:38:58.478033Z",
     "shell.execute_reply": "2025-12-18T11:38:58.477437Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# urls = [\"https://drive.google.com/file/d/10cecNtR3VsHfV0N-gNEeoVeB89kCnse5/view?usp=drive_link\",\n",
    "#         \"https://drive.google.com/file/d/1Kadc6CUTb4opVSDE4x6RFFnEy0P1cRp0/view?usp=drive_link\"]\n",
    "# for url in urls:\n",
    "#     gdown.download(url, quiet=False, use_cookies=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.479988Z",
     "iopub.status.busy": "2025-12-18T11:38:58.479820Z",
     "iopub.status.idle": "2025-12-18T11:38:58.482250Z",
     "shell.execute_reply": "2025-12-18T11:38:58.481862Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.483931Z",
     "iopub.status.busy": "2025-12-18T11:38:58.483776Z",
     "iopub.status.idle": "2025-12-18T11:38:58.486296Z",
     "shell.execute_reply": "2025-12-18T11:38:58.485915Z"
    },
    "id": "nM7KaeCbA_mQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.488113Z",
     "iopub.status.busy": "2025-12-18T11:38:58.487939Z",
     "iopub.status.idle": "2025-12-18T11:38:58.503351Z",
     "shell.execute_reply": "2025-12-18T11:38:58.502877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_uuid(line):\n",
    "    pattern_uuid = re.compile(r'uuid\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_uuid.findall(line)\n",
    "\n",
    "def extract_subject_type(line):\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    return pattern_type.findall(line)\n",
    "\n",
    "def show(file_path):\n",
    "    print(f\"Processing {file_path}\")\n",
    "\n",
    "def extract_edge_info(line):\n",
    "    pattern_src = re.compile(r'subject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst1 = re.compile(r'predicateObject\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_dst2 = re.compile(r'predicateObject2\\\":{\\\"com.bbn.tc.schema.avro.cdm18.UUID\\\":\\\"(.*?)\\\"}')\n",
    "    pattern_type = re.compile(r'type\\\":\\\"(.*?)\\\"')\n",
    "    pattern_time = re.compile(r'timestampNanos\\\":(.*?),')\n",
    "\n",
    "    edge_type = extract_subject_type(line)[0]\n",
    "    timestamp = pattern_time.findall(line)[0]\n",
    "    src_id = pattern_src.findall(line)\n",
    "\n",
    "    if len(src_id) == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    src_id = src_id[0]\n",
    "    dst_id1 = pattern_dst1.findall(line)\n",
    "    dst_id2 = pattern_dst2.findall(line)\n",
    "\n",
    "    if len(dst_id1) > 0 and dst_id1[0] != 'null':\n",
    "        dst_id1 = dst_id1[0]\n",
    "    else:\n",
    "        dst_id1 = None\n",
    "\n",
    "    if len(dst_id2) > 0 and dst_id2[0] != 'null':\n",
    "        dst_id2 = dst_id2[0]\n",
    "    else:\n",
    "        dst_id2 = None\n",
    "\n",
    "    return src_id, edge_type, timestamp, dst_id1, dst_id2\n",
    "\n",
    "def process_data(file_path):\n",
    "    id_nodetype_map = {}\n",
    "    notice_num = 1000000\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f:\n",
    "            show(now_path)\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line or 'com.bbn.tc.schema.avro.cdm18.Host' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.TimeMarker' in line or 'com.bbn.tc.schema.avro.cdm18.StartMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.UnitDependency' in line or 'com.bbn.tc.schema.avro.cdm18.EndMarker' in line:\n",
    "                    continue\n",
    "\n",
    "                uuid = extract_uuid(line)[0]\n",
    "                subject_type = extract_subject_type(line)\n",
    "\n",
    "                if len(subject_type) < 1:\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.MemoryObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'MemoryObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.NetFlowObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'NetFlowObject'\n",
    "                        continue\n",
    "                    if 'com.bbn.tc.schema.avro.cdm18.UnnamedPipeObject' in line:\n",
    "                        id_nodetype_map[uuid] = 'UnnamedPipeObject'\n",
    "                        continue\n",
    "\n",
    "                id_nodetype_map[uuid] = subject_type[0]\n",
    "\n",
    "    return id_nodetype_map\n",
    "\n",
    "def process_edges(file_path, id_nodetype_map):\n",
    "    notice_num = 1000000\n",
    "    not_in_cnt = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        now_path = file_path + '.' + str(i)\n",
    "        if i == 0:\n",
    "            now_path = file_path\n",
    "        if not os.path.exists(now_path):\n",
    "            break\n",
    "\n",
    "        with open(now_path, 'r') as f, open(now_path+'.txt', 'w') as fw:\n",
    "            cnt = 0\n",
    "            for line in f:\n",
    "                cnt += 1\n",
    "                if cnt % notice_num == 0:\n",
    "                    print(cnt)\n",
    "\n",
    "                if 'com.bbn.tc.schema.avro.cdm18.Event' in line:\n",
    "                    src_id, edge_type, timestamp, dst_id1, dst_id2 = extract_edge_info(line)\n",
    "\n",
    "                    if src_id is None or src_id not in id_nodetype_map:\n",
    "                        not_in_cnt += 1\n",
    "                        continue\n",
    "\n",
    "                    src_type = id_nodetype_map[src_id]\n",
    "\n",
    "                    if dst_id1 is not None and dst_id1 in id_nodetype_map:\n",
    "                        dst_type1 = id_nodetype_map[dst_id1]\n",
    "                        this_edge1 = f\"{src_id}\\t{src_type}\\t{dst_id1}\\t{dst_type1}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge1)\n",
    "\n",
    "                    if dst_id2 is not None and dst_id2 in id_nodetype_map:\n",
    "                        dst_type2 = id_nodetype_map[dst_id2]\n",
    "                        this_edge2 = f\"{src_id}\\t{src_type}\\t{dst_id2}\\t{dst_type2}\\t{edge_type}\\t{timestamp}\\n\"\n",
    "                        fw.write(this_edge2)\n",
    "\n",
    "def run_data_processing():\n",
    "    os.system('tar -zxvf ta1-theia-e3-official-1r.json.tar.gz')\n",
    "    os.system('tar -zxvf ta1-theia-e3-official-6r.json.tar.gz')\n",
    "    \n",
    "    path_list = ['ta1-theia-e3-official-1r.json', 'ta1-theia-e3-official-6r.json']\n",
    "\n",
    "    for path in path_list:\n",
    "        id_nodetype_map = process_data(path)\n",
    "        process_edges(path, id_nodetype_map)\n",
    "\n",
    "    os.system('cp ta1-theia-e3-official-1r.json.txt theia_train.txt')\n",
    "    os.system('cp ta1-theia-e3-official-6r.json.8.txt theia_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.505372Z",
     "iopub.status.busy": "2025-12-18T11:38:58.505022Z",
     "iopub.status.idle": "2025-12-18T11:38:58.507185Z",
     "shell.execute_reply": "2025-12-18T11:38:58.506812Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.509059Z",
     "iopub.status.busy": "2025-12-18T11:38:58.508915Z",
     "iopub.status.idle": "2025-12-18T11:38:58.519325Z",
     "shell.execute_reply": "2025-12-18T11:38:58.518844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_node_properties(nodes, node_id, properties):\n",
    "    if node_id not in nodes:\n",
    "        nodes[node_id] = []\n",
    "    nodes[node_id].extend(properties)\n",
    "\n",
    "def update_edge_index(edges, edge_index, index):\n",
    "    for src_id, dst_id in edges:\n",
    "        src = index[src_id]\n",
    "        dst = index[dst_id]\n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)\n",
    "\n",
    "def prepare_graph(df):\n",
    "    nodes, labels, edges = {}, {}, []\n",
    "    dummies = {\"SUBJECT_PROCESS\":\t0, \"MemoryObject\":\t1, \"FILE_OBJECT_BLOCK\":\t2,\n",
    "               \"NetFlowObject\":\t3,\"PRINCIPAL_REMOTE\":\t4,'PRINCIPAL_LOCAL':5}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = row[\"action\"]\n",
    "        properties = [row['exec'], action] + ([row['path']] if row['path'] else [])\n",
    "        \n",
    "        actor_id = row[\"actorID\"]\n",
    "        add_node_properties(nodes, actor_id, properties)\n",
    "        labels[actor_id] = dummies[row['actor_type']]\n",
    "\n",
    "        object_id = row[\"objectID\"]\n",
    "        add_node_properties(nodes, object_id, properties)\n",
    "        labels[object_id] = dummies[row['object']]\n",
    "\n",
    "        edges.append((actor_id, object_id))\n",
    "\n",
    "    features, feat_labels, edge_index, index_map = [], [], [[], []], {}\n",
    "    for node_id, props in nodes.items():\n",
    "        features.append(props)\n",
    "        feat_labels.append(labels[node_id])\n",
    "        index_map[node_id] = len(features) - 1\n",
    "\n",
    "    update_edge_index(edges, edge_index, index_map)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(index_map.keys()), index_map\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def add_csv_edges_efficient(original_features, original_labels, original_edge_index, original_mapp, original_mapidx, csv_path, thres=450): \n",
    "    csv_edges = []\n",
    "    csv_nodes = set()\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            src_id, dst_id = row[0], row[1]\n",
    "            csv_edges.append((src_id, dst_id))\n",
    "            csv_nodes.add(src_id)\n",
    "            csv_nodes.add(dst_id)\n",
    "    \n",
    "    extended_features = original_features.copy()\n",
    "    extended_labels = original_labels.copy()\n",
    "    extended_edge_index = [original_edge_index[0].copy(), original_edge_index[1].copy()]\n",
    "    extended_mapp = original_mapp.copy()\n",
    "    extended_mapidx = original_mapidx.copy()\n",
    "\n",
    "    degrees = defaultdict(int)\n",
    "    for src_idx in extended_edge_index[0]:\n",
    "        degrees[src_idx] += 1\n",
    "    for dst_idx in extended_edge_index[1]:\n",
    "        degrees[dst_idx] += 1\n",
    "    \n",
    "    all_degrees = list(degrees.values())\n",
    "    all_degrees.sort(reverse=True)\n",
    "    print(all_degrees[:3000])\n",
    "\n",
    "    count1, count2, count3 = 0, 0, 0\n",
    "    for src_id, dst_id in csv_edges:\n",
    "        if src_id in extended_mapidx and dst_id in extended_mapidx:\n",
    "            src_idx = extended_mapidx[src_id]\n",
    "            dst_idx = extended_mapidx[dst_id]\n",
    "            if degrees[src_idx] <= thres and degrees[dst_idx] <= thres:\n",
    "                extended_edge_index[0].append(src_idx)\n",
    "                extended_edge_index[1].append(dst_idx)\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1\n",
    "        else:\n",
    "            count3 += 1\n",
    "    print(f'Sucessfully add edges: {count1}\\tPrune edges: {count2}\\tFail to add edges: {count3}')\n",
    "    \n",
    "    return extended_features, extended_labels, extended_edge_index, extended_mapp, extended_mapidx\n",
    "\n",
    "dummies = {\n",
    "    \"SUBJECT_PROCESS\": 0, \n",
    "    \"MemoryObject\": 1, \n",
    "    \"FILE_OBJECT_BLOCK\": 2,\n",
    "    \"NetFlowObject\": 3, \n",
    "    \"PRINCIPAL_REMOTE\": 4, \n",
    "    \"PRINCIPAL_LOCAL\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.521140Z",
     "iopub.status.busy": "2025-12-18T11:38:58.520986Z",
     "iopub.status.idle": "2025-12-18T11:38:58.525128Z",
     "shell.execute_reply": "2025-12-18T11:38:58.524648Z"
    },
    "id": "fmXWs1dKIzD8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, out_channel, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.526859Z",
     "iopub.status.busy": "2025-12-18T11:38:58.526703Z",
     "iopub.status.idle": "2025-12-18T11:38:58.529984Z",
     "shell.execute_reply": "2025-12-18T11:38:58.529589Z"
    },
    "id": "YBuP_tSq94f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.531747Z",
     "iopub.status.busy": "2025-12-18T11:38:58.531595Z",
     "iopub.status.idle": "2025-12-18T11:38:58.602882Z",
     "shell.execute_reply": "2025-12-18T11:38:58.602239Z"
    },
    "id": "3PCP6SXwZaif",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('word2vec_theia_E3.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.604939Z",
     "iopub.status.busy": "2025-12-18T11:38:58.604772Z",
     "iopub.status.idle": "2025-12-18T11:38:58.608133Z",
     "shell.execute_reply": "2025-12-18T11:38:58.607690Z"
    },
    "id": "P8oBL8LFaeOf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.609908Z",
     "iopub.status.busy": "2025-12-18T11:38:58.609753Z",
     "iopub.status.idle": "2025-12-18T11:38:58.612119Z",
     "shell.execute_reply": "2025-12-18T11:38:58.611725Z"
    },
    "id": "Se7Ei4tAapVj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.613881Z",
     "iopub.status.busy": "2025-12-18T11:38:58.613726Z",
     "iopub.status.idle": "2025-12-18T11:38:58.620584Z",
     "shell.execute_reply": "2025-12-18T11:38:58.619698Z"
    },
    "id": "3RDmGME5iPb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_attributes(d,p):\n",
    "    \n",
    "    f = open(p)\n",
    "    data = [json.loads(x) for x in f if \"EVENT\" in x]\n",
    "\n",
    "    info = []\n",
    "    for x in data:\n",
    "        try:\n",
    "            action = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['type']\n",
    "        except:\n",
    "            action = ''\n",
    "        try:\n",
    "            actor = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['subject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            actor = ''\n",
    "        try:\n",
    "            obj = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            obj = ''\n",
    "        try:\n",
    "            timestamp = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['timestampNanos']\n",
    "        except:\n",
    "            timestamp = ''\n",
    "        try:\n",
    "            cmd = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['properties']['map']['cmdLine']\n",
    "        except:\n",
    "            cmd = ''\n",
    "        try:\n",
    "            path = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObjectPath']['string']\n",
    "        except:\n",
    "            path = ''\n",
    "        try:\n",
    "            path2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2Path']['string']\n",
    "        except:\n",
    "            path2 = ''\n",
    "        try:\n",
    "            obj2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "            info.append({'actorID':actor,'objectID':obj2,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path2})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        info.append({'actorID':actor,'objectID':obj,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path})\n",
    "\n",
    "    rdf = pd.DataFrame.from_records(info).astype(str)\n",
    "    d = d.astype(str)\n",
    "\n",
    "    return d.merge(rdf,how='inner',on=['actorID','objectID','action','timestamp']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:38:58.622634Z",
     "iopub.status.busy": "2025-12-18T11:38:58.622379Z",
     "iopub.status.idle": "2025-12-18T11:49:57.831733Z",
     "shell.execute_reply": "2025-12-18T11:49:57.820858Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4562183, 587918, 478532, 293166, 287352, 159288, 108047, 106861, 105276, 103333, 103221, 103175, 102759, 97894, 96485, 95877, 94765, 94565, 94561, 93899, 93647, 93627, 93609, 93509, 93135, 92213, 91707, 91607, 91527, 91501, 90943, 90273, 90031, 89925, 89759, 89723, 89471, 89275, 89241, 89203, 89185, 88577, 88062, 85165, 84301, 84227, 83485, 83247, 82279, 81971, 81971, 81953, 81889, 81879, 81599, 80981, 80827, 80495, 80485, 80379, 80359, 80315, 79979, 79449, 78887, 78321, 77677, 77159, 76531, 60221, 26958, 22604, 21801, 19547, 18228, 18089, 15408, 15215, 14394, 12828, 9871, 9426, 9249, 9137, 9137, 9137, 9056, 8723, 8712, 8573, 8556, 8447, 8444, 8443, 8443, 8443, 8443, 8443, 8335, 8335, 8335, 8331, 8331, 8189, 7963, 7963, 7963, 7963, 7855, 7855, 7855, 7855, 7855, 7855, 7855, 7855, 7851, 7851, 7851, 7851, 7851, 7851, 7851, 7851, 7851, 7773, 7601, 7539, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7537, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7533, 7441, 7431, 7379, 7373, 7347, 7313, 7281, 7239, 7179, 7156, 7048, 6909, 6817, 6767, 6725, 6627, 6609, 6605, 6545, 6541, 6498, 6421, 6289, 6179, 5945, 5836, 5700, 5672, 5354, 4991, 4807, 4799, 4757, 4739, 4727, 4717, 4699, 4695, 4689, 4679, 4671, 4657, 4647, 4645, 4643, 4631, 4623, 4361, 4281, 4263, 4234, 4202, 4192, 4098, 4093, 3977, 3945, 3915, 3899, 3895, 3891, 3883, 3879, 3879, 3873, 3861, 3853, 3837, 3835, 3807, 3803, 3803, 3803, 3795, 3795, 3795, 3791, 3791, 3791, 3779, 3779, 3779, 3779, 3779, 3779, 3771, 3763, 3763, 3747, 3739, 3733, 3729, 3727, 3727, 3719, 3713, 3711, 3711, 3711, 3711, 3711, 3711, 3703, 3687, 3687, 3651, 3631, 3631, 3631, 3631, 3631, 3631, 3631, 3631, 3615, 3615, 3615, 3615, 3615, 3611, 3607, 3607, 3607, 3607, 3587, 3576, 3561, 3532, 3468, 3283, 3271, 3241, 3223, 3203, 3201, 3197, 3159, 3137, 3055, 3013, 2994, 2994, 2994, 2994, 2887, 2872, 2872, 2856, 2849, 2840, 2837, 2811, 2784, 2780, 2774, 2742, 2702, 2698, 2657, 2642, 2642, 2642, 2642, 2618, 2617, 2607, 2598, 2598, 2588, 2561, 2543, 2541, 2540, 2539, 2531, 2515, 2509, 2495, 2489, 2481, 2481, 2477, 2475, 2471, 2463, 2457, 2451, 2449, 2445, 2429, 2427, 2419, 2419, 2413, 2411, 2411, 2403, 2397, 2395, 2395, 2387, 2381, 2381, 2379, 2379, 2373, 2349, 2328, 2321, 2309, 2309, 2309, 2308, 2308, 2308, 2308, 2307, 2307, 2307, 2307, 2301, 2301, 2301, 2300, 2299, 2299, 2299, 2299, 2299, 2293, 2291, 2285, 2285, 2277, 2277, 2275, 2275, 2269, 2269, 2269, 2269, 2267, 2267, 2267, 2251, 2229, 2197, 2189, 2187, 2181, 2181, 2181, 2179, 2179, 2179, 2179, 2177, 2177, 2177, 2177, 2175, 2175, 2171, 2169, 2165, 2163, 2157, 2155, 2155, 2147, 2147, 2113, 2093, 2089, 2089, 2087, 2087, 2087, 2087, 2087, 2087, 2071, 2069, 2069, 2069, 2069, 2069, 2067, 2067, 2067, 2067, 2067, 2067, 2067, 2064, 2046, 2026, 2023, 2003, 1913, 1912, 1867, 1853, 1848, 1848, 1845, 1843, 1835, 1831, 1829, 1829, 1827, 1827, 1827, 1827, 1827, 1824, 1824, 1824, 1823, 1821, 1820, 1817, 1817, 1811, 1809, 1809, 1807, 1806, 1803, 1797, 1781, 1765, 1763, 1758, 1754, 1752, 1752, 1745, 1745, 1745, 1743, 1741, 1739, 1731, 1729, 1722, 1721, 1721, 1721, 1721, 1719, 1719, 1711, 1701, 1681, 1680, 1669, 1651, 1649, 1649, 1637, 1635, 1628, 1624, 1624, 1617, 1603, 1596, 1560, 1560, 1549, 1547, 1534, 1533, 1510, 1509, 1506, 1498, 1496, 1492, 1492, 1480, 1474, 1459, 1455, 1452, 1435, 1431, 1421, 1411, 1405, 1399, 1397, 1395, 1393, 1393, 1391, 1389, 1385, 1381, 1381, 1379, 1369, 1355, 1352, 1348, 1345, 1345, 1344, 1342, 1339, 1339, 1338, 1338, 1331, 1323, 1318, 1314, 1313, 1305, 1305, 1305, 1305, 1305, 1303, 1301, 1299, 1297, 1295, 1295, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1285, 1250, 1249, 1231, 1227, 1222, 1222, 1222, 1220, 1215, 1215, 1214, 1212, 1212, 1201, 1200, 1195, 1191, 1183, 1171, 1170, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1165, 1163, 1163, 1162, 1161, 1158, 1157, 1150, 1146, 1144, 1143, 1139, 1135, 1135, 1131, 1129, 1112, 1088, 1087, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1067, 1049, 1049, 1049, 1040, 1021, 1020, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1018, 1015, 1011, 1001, 1001, 999, 991, 989, 987, 987, 984, 983, 983, 982, 980, 979, 977, 974, 963, 963, 962, 962, 960, 960, 958, 958, 957, 957, 954, 954, 952, 949, 948, 948, 946, 945, 945, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 941, 940, 929, 924, 923, 916, 913, 913, 912, 912, 912, 912, 912, 912, 912, 912, 912, 912, 909, 904, 904, 903, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 889, 885, 881, 876, 853, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 851, 848, 844, 827, 825, 825, 825, 823, 821, 817, 817, 817, 817, 815, 815, 813, 813, 807, 805, 805, 805, 802, 792, 785, 783, 782, 780, 778, 778, 776, 776, 774, 774, 772, 769, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 763, 756, 755, 755, 755, 753, 753, 750, 750, 750, 750, 750, 750, 750, 750, 750, 750, 750, 750, 750, 750, 747, 745, 741, 741, 741, 737, 735, 735, 733, 731, 731, 729, 725, 725, 725, 725, 723, 721, 720, 720, 720, 719, 715, 714, 697, 693, 663, 662, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 632, 617, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 600, 588, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 586, 586, 585, 584, 584, 580, 580, 580, 580, 580, 579, 576, 567, 565, 565, 559, 557, 555, 555, 554, 553, 551, 551, 551, 549, 549, 549, 547, 547, 547, 546, 543, 543, 539, 524, 515, 515, 510, 509, 509, 508, 508, 504, 504, 504, 504, 500, 497, 495, 481, 480, 479, 479, 477, 475, 475, 473, 473, 467, 465, 463, 463, 463, 461, 458, 458, 458, 458, 458, 458, 457, 457, 457, 457, 455, 455, 455, 455, 450, 449, 447, 447, 443, 443, 438, 437, 432, 429, 429, 427, 427, 424, 424, 423, 423, 420, 419, 417, 416, 415, 415, 415, 415, 412, 412, 412, 412, 412, 412, 412, 409, 409, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 407, 407, 404, 404, 404, 404, 404, 404, 403, 403, 401, 401, 397, 395, 393, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 391, 387, 387, 387, 387, 387, 387, 387, 385, 385, 385, 381, 381, 375, 375, 375, 375, 375, 375, 375, 371, 371, 371, 369, 369, 369, 369, 369, 369, 368, 367, 367, 366, 366, 366, 364, 363, 363, 362, 361, 361, 361, 361, 361, 361, 361, 361, 361, 360, 355, 355, 355, 354, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 351, 349, 349, 347, 347, 347, 347, 347, 347, 347, 347, 345, 345, 342, 342, 342, 342, 342, 342, 341, 341, 341, 341, 341, 341, 341, 339, 335, 334, 333, 333, 333, 333, 333, 333, 333, 333, 333, 332, 330, 328, 327, 327, 327, 327, 327, 327, 327, 327, 327, 325, 325, 325, 322, 321, 321, 321, 321, 321, 321, 321, 320, 320, 317, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 311, 311, 311, 311, 311, 311, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 308, 307, 307, 307, 307, 306, 306, 306, 306, 306, 305, 305, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 303, 301, 301, 301, 301, 300, 299, 299, 299, 297, 297, 297, 295, 295, 295, 294, 294, 293, 293, 293, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 291, 290, 289, 289, 289, 289, 287, 285, 285, 285, 283, 283, 283, 283, 283, 281, 281, 281, 279, 279, 279, 279, 278, 277, 277, 277, 277, 277, 277, 277, 277, 277, 276, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 274, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 271, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 269, 267, 266, 265, 265, 265, 264, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 263, 262, 262, 262, 262, 261, 261, 260, 260, 259, 259, 259, 259, 259, 259, 259, 257, 257, 257, 257, 257, 257, 256, 255, 255, 255, 253, 253, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 251, 250, 250, 249, 249, 249, 249, 248, 248, 248, 248, 248, 247, 247, 247, 247, 247, 247, 246, 245, 245, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 243, 243, 243, 243, 243, 243, 243, 243, 242, 242, 241, 241, 241, 241, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 239, 239, 239, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 237, 236, 236, 236, 235, 235, 234, 234, 234, 233, 233, 232, 232, 231, 231, 231, 231, 231, 231, 231, 231, 230, 229, 229, 229, 228, 227, 227, 227, 227, 226, 225, 223, 222, 221, 221, 221, 220, 220, 220, 220, 220, 220, 219, 219, 219, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 216, 216, 216, 216, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 215, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 212, 212, 212, 211, 211, 209, 208, 208, 207, 207, 207, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 205, 205, 205, 205, 205, 205, 205, 205, 205, 205, 204, 204, 204, 204, 204, 204, 204, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 202, 202, 202, 202, 202, 201, 201, 200, 200, 199, 199, 199, 199, 198, 198, 198, 197, 197, 197, 195, 193, 193, 193, 193, 193, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 188, 188, 188, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 184, 184, 184, 183, 183, 183, 183, 183, 182, 182, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 180, 180, 180, 180, 180, 180, 178, 178, 178, 177, 177, 176, 176, 176, 176, 176, 176, 176, 175, 175, 175, 174, 174, 174, 174, 174, 174, 174, 174, 174, 173, 173, 173, 173, 173, 172, 172, 172, 172, 172, 172, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 170, 170, 169, 169, 169, 169, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 166, 166, 166, 166, 166, 166]\n",
      "Sucessfully add edges: 134\tPrune edges: 1289\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "if Train:\n",
    "    f = open(\"../theia_train.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df = df.dropna()\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = add_attributes(df,\"../ta1-theia-e3-official-1r.json\")\n",
    "    phrases,labels,edges,mapp,mapidx = prepare_graph(df)\n",
    "    csv_path = \"../../flash-add-edge/theia_train.csv\"\n",
    "    phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "        phrases, labels, edges, mapp, mapidx, csv_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:49:57.834818Z",
     "iopub.status.busy": "2025-12-18T11:49:57.834463Z",
     "iopub.status.idle": "2025-12-18T11:49:58.169265Z",
     "shell.execute_reply": "2025-12-18T11:49:58.168675Z"
    },
    "id": "p3TAi69zI1bO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# model = GCN(30,5).to(device)\n",
    "model = GCN(10,5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:49:58.173172Z",
     "iopub.status.busy": "2025-12-18T11:49:58.172997Z",
     "iopub.status.idle": "2025-12-18T11:49:58.175752Z",
     "shell.execute_reply": "2025-12-18T11:49:58.175233Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:49:58.177170Z",
     "iopub.status.busy": "2025-12-18T11:49:58.177016Z",
     "iopub.status.idle": "2025-12-18T11:49:58.179422Z",
     "shell.execute_reply": "2025-12-18T11:49:58.178907Z"
    }
   },
   "outputs": [],
   "source": [
    "# if Train:\n",
    "#     word2vec = Word2Vec(sentences=phrases, vector_size=10, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:49:58.180829Z",
     "iopub.status.busy": "2025-12-18T11:49:58.180689Z",
     "iopub.status.idle": "2025-12-18T11:49:58.415839Z",
     "shell.execute_reply": "2025-12-18T11:49:58.415300Z"
    },
    "id": "Vn_pMyt5Jd-6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000):\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "def infer(document):\n",
    "    word_embeddings = [w2vmodel.wv[word] for word in document if word in w2vmodel.wv]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(10)\n",
    "    \n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    mean_embedding = np.mean(output_embedding, axis=0)\n",
    "    \n",
    "    return mean_embedding\n",
    "\n",
    "# encoder = PositionalEncoder(30)\n",
    "encoder = PositionalEncoder(10)\n",
    "# w2vmodel = Word2Vec.load(\"trained_weights/theia/word2vec_theia_E3.model\")\n",
    "w2vmodel = Word2Vec.load(\"../word2vec_theia_E3.model\")\n",
    "print(w2vmodel.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-18T11:49:58.418238Z",
     "iopub.status.busy": "2025-12-18T11:49:58.417977Z",
     "iopub.status.idle": "2025-12-18T11:52:18.761304Z",
     "shell.execute_reply": "2025-12-18T11:52:18.760593Z"
    },
    "executionInfo": {
     "elapsed": 689309,
     "status": "ok",
     "timestamp": 1673566932746,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "f60fadea-a7db-471f-defe-fee744f6ef25",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9756219958490788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 22039 nodes still misclassified \n",
      "\n",
      "1.4622583786682586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 2536 nodes still misclassified \n",
      "\n",
      "1.3498218059539795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 2. 676 nodes still misclassified \n",
      "\n",
      "1.3431310653686523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 3. 404 nodes still misclassified \n",
      "\n",
      "1.3065234422683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 4. 327 nodes still misclassified \n",
      "\n",
      "1.2742927074432373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 5. 323 nodes still misclassified \n",
      "\n",
      "1.2448513507843018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 6. 280 nodes still misclassified \n",
      "\n",
      "1.2402883768081665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 7. 212 nodes still misclassified \n",
      "\n",
      "1.2420943975448608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 8. 191 nodes still misclassified \n",
      "\n",
      "1.2340220212936401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 9. 188 nodes still misclassified \n",
      "\n",
      "1.211233377456665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 188 nodes still misclassified \n",
      "\n",
      "1.2014905214309692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 188 nodes still misclassified \n",
      "\n",
      "1.1968824863433838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 188 nodes still misclassified \n",
      "\n",
      "1.1857988834381104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 188 nodes still misclassified \n",
      "\n",
      "1.1734411716461182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 14. 188 nodes still misclassified \n",
      "\n",
      "1.1660728454589844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 188 nodes still misclassified \n",
      "\n",
      "1.153607726097107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 188 nodes still misclassified \n",
      "\n",
      "1.1427656412124634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 188 nodes still misclassified \n",
      "\n",
      "1.1349046230316162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 188 nodes still misclassified \n",
      "\n",
      "1.132891297340393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 188 nodes still misclassified \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "if Train:\n",
    "    l = np.array(labels)\n",
    "    \n",
    "    ngram_class_weights = [\n",
    "        1.1362,\n",
    "        1.5000,\n",
    "        1.2052,\n",
    "        0.5000,\n",
    "        1.0000,\n",
    "    ]\n",
    "    class_weights = torch.tensor(ngram_class_weights,dtype=torch.float).to(device)\n",
    "    \n",
    "    \n",
    "    criterion = CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes)\n",
    "    mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for m_n in range(20):\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      total_loss = 0\n",
    "      for subg in loader:\n",
    "          model.train()\n",
    "          optimizer.zero_grad() \n",
    "          out = model(subg.x, subg.edge_index) \n",
    "          loss = criterion(out, subg.y) \n",
    "          loss.backward() \n",
    "          optimizer.step()      \n",
    "          total_loss += loss.item() * subg.batch_size\n",
    "      print(total_loss / mask.sum().item())\n",
    "\n",
    "      loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "      for subg in loader:\n",
    "          model.eval()\n",
    "          out = model(subg.x, subg.edge_index)\n",
    "\n",
    "          sorted, indices = out.sort(dim=1,descending=True)\n",
    "          conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "          conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "          pred = indices[:,0]\n",
    "          cond = (pred == subg.y) | (conf >= 0.9)\n",
    "          subg.n_id = subg.n_id.to(device)\n",
    "          mask[subg.n_id[cond]] = False\n",
    "\n",
    "      torch.save(model.state_dict(), f'lword2vec_gnn_theia{m_n}_E3.pth')\n",
    "      print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:52:18.764165Z",
     "iopub.status.busy": "2025-12-18T11:52:18.763970Z",
     "iopub.status.idle": "2025-12-18T11:52:18.780858Z",
     "shell.execute_reply": "2025-12-18T11:52:18.780125Z"
    },
    "id": "vgqyu7E5qPet",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def Get_Adjacent(ids, mapp, edges, hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    \n",
    "    neighbors = set()\n",
    "    for edge in zip(edges[0], edges[1]):\n",
    "        if any(mapp[node] in ids for node in edge):\n",
    "            neighbors.update(mapp[node] for node in edge)\n",
    "\n",
    "    if hops > 1:\n",
    "        neighbors = neighbors.union(Get_Adjacent(neighbors, mapp, edges, hops - 1))\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def calculate_metrics(TP, FP, FN, TN):\n",
    "    FPR = FP / (FP + TN) if FP + TN > 0 else 0\n",
    "    TPR = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    prec = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    rec = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    fscore = (2 * prec * rec) / (prec + rec) if prec + rec > 0 else 0\n",
    "\n",
    "    return prec, rec, fscore, FPR, TPR\n",
    "\n",
    "def helper(MP, all_pids, GP, edges, mapp):\n",
    "    TP = MP.intersection(GP)\n",
    "    FP = MP - GP\n",
    "    FN = GP - MP\n",
    "    TN = all_pids - (GP | MP)\n",
    "\n",
    "    two_hop_gp = Get_Adjacent(GP, mapp, edges, 2)\n",
    "    two_hop_tp = Get_Adjacent(TP, mapp, edges, 2)\n",
    "    FPL = FP - two_hop_gp\n",
    "    TPL = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "\n",
    "    TP, FP, FN, TN = len(TPL), len(FPL), len(FN), len(TN)\n",
    "\n",
    "    prec, rec, fscore, FPR, TPR = calculate_metrics(TP, FP, FN, TN)\n",
    "    print(f\"True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN}\")\n",
    "    print(f\"Precision: {round(prec, 2)}, Recall: {round(rec, 2)}, Fscore: {round(fscore, 2)}\")\n",
    "    \n",
    "    return TPL, FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:52:18.783018Z",
     "iopub.status.busy": "2025-12-18T11:52:18.782855Z",
     "iopub.status.idle": "2025-12-18T11:53:10.605415Z",
     "shell.execute_reply": "2025-12-18T11:53:10.604486Z"
    },
    "id": "OZFrSLVZ29qU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"../theia_test.txt\")\n",
    "data = f.read().split('\\n')\n",
    "data = [line.split('\\t') for line in data]\n",
    "df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "df = df.dropna()\n",
    "df.sort_values(by='timestamp', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:53:10.608468Z",
     "iopub.status.busy": "2025-12-18T11:53:10.608257Z",
     "iopub.status.idle": "2025-12-18T11:57:29.768994Z",
     "shell.execute_reply": "2025-12-18T11:57:29.768017Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = add_attributes(df,\"../ta1-theia-e3-official-6r.json.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T11:57:29.773308Z",
     "iopub.status.busy": "2025-12-18T11:57:29.773091Z",
     "iopub.status.idle": "2025-12-18T12:07:54.262101Z",
     "shell.execute_reply": "2025-12-18T12:07:54.260902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4584961, 1847753, 1020801, 676112, 170387, 127358, 117043, 102915, 102855, 98418, 95039, 91235, 90815, 90721, 90417, 89345, 89213, 89125, 89065, 88865, 85825, 84473, 84307, 83455, 83255, 82893, 82713, 82671, 82609, 82427, 82105, 81673, 75063, 75027, 75009, 74997, 74987, 74949, 74909, 68077, 41797, 39673, 37983, 37543, 37335, 36511, 35913, 35229, 34890, 33059, 32991, 32323, 31611, 30423, 30279, 29703, 28569, 27549, 27219, 26594, 26059, 25483, 24571, 24309, 23273, 22598, 22527, 21065, 20571, 19899, 19743, 18973, 18899, 18847, 18683, 18480, 18421, 17556, 16413, 16317, 15955, 15887, 14966, 14752, 13861, 13539, 13505, 12899, 12876, 12793, 12768, 11767, 11221, 10995, 10937, 10925, 10903, 10641, 10544, 10358, 10321, 10273, 10269, 10269, 10080, 9787, 9363, 9305, 9135, 9131, 9129, 9125, 8835, 8801, 8797, 8795, 8795, 8685, 8658, 8607, 8497, 8493, 8491, 8325, 8323, 8054, 7949, 7927, 7921, 7913, 7853, 7847, 7847, 7845, 7845, 7843, 7843, 7843, 7843, 7841, 7841, 7841, 7839, 7837, 7837, 7837, 7837, 7835, 7833, 7831, 7831, 7827, 7775, 7597, 7523, 7519, 7519, 7519, 7517, 7517, 7517, 7517, 7517, 7515, 7515, 7515, 7513, 7513, 7513, 7513, 7513, 7513, 7511, 7511, 7511, 7511, 7511, 7511, 7511, 7511, 7511, 7509, 7452, 7449, 7414, 7372, 7371, 7175, 7163, 6987, 6959, 6910, 6863, 6551, 6547, 6485, 6481, 6474, 6451, 6435, 6425, 6417, 6403, 6403, 6393, 6393, 6393, 6393, 6387, 6383, 6383, 6381, 6377, 6375, 6373, 6363, 6335, 6321, 6195, 6193, 6113, 6113, 6109, 6103, 6095, 6077, 6071, 6071, 6069, 6069, 6039, 6035, 6035, 5997, 5995, 5991, 5987, 5985, 5975, 5953, 5949, 5839, 5836, 5299, 5101, 5086, 5007, 4983, 4961, 4959, 4917, 4863, 4861, 4859, 4857, 4857, 4855, 4815, 4807, 4807, 4805, 4805, 4803, 4801, 4777, 4773, 4681, 4679, 4679, 4677, 4677, 4673, 4629, 4629, 4581, 4523, 4501, 4496, 4489, 4489, 4485, 4483, 4483, 4479, 4443, 4419, 4417, 4417, 4397, 4337, 4245, 4103, 4035, 3969, 3939, 3905, 3741, 3729, 3715, 3679, 3639, 3611, 3594, 3591, 3455, 3433, 3399, 3350, 3335, 3281, 3279, 3266, 3144, 3121, 3119, 3115, 3085, 3081, 3077, 3073, 3009, 3005, 3003, 3001, 2981, 2973, 2963, 2841, 2802, 2728, 2718, 2697, 2682, 2663, 2654, 2653, 2651, 2639, 2638, 2610, 2539, 2521, 2509, 2503, 2501, 2499, 2487, 2475, 2473, 2471, 2461, 2421, 2411, 2409, 2409, 2393, 2393, 2391, 2391, 2391, 2391, 2391, 2389, 2389, 2389, 2389, 2389, 2389, 2389, 2389, 2389, 2387, 2387, 2387, 2387, 2387, 2387, 2385, 2385, 2385, 2385, 2385, 2383, 2378, 2361, 2337, 2335, 2335, 2335, 2333, 2327, 2303, 2299, 2299, 2299, 2298, 2297, 2295, 2295, 2291, 2291, 2287, 2287, 2283, 2283, 2282, 2280, 2278, 2276, 2275, 2267, 2255, 2251, 2230, 2229, 2225, 2225, 2189, 2189, 2188, 2187, 2187, 2185, 2179, 2179, 2179, 2179, 2175, 2175, 2175, 2173, 2173, 2171, 2167, 2165, 2164, 2164, 2163, 2158, 2155, 2103, 2103, 2095, 2091, 2091, 2091, 2091, 2091, 2089, 2089, 2088, 2088, 2087, 2087, 2086, 2085, 2083, 2083, 2065, 2056, 1993, 1991, 1989, 1959, 1947, 1939, 1927, 1921, 1915, 1913, 1907, 1899, 1887, 1872, 1829, 1827, 1825, 1811, 1811, 1810, 1807, 1803, 1790, 1787, 1783, 1783, 1781, 1773, 1761, 1751, 1745, 1745, 1745, 1745, 1743, 1743, 1743, 1743, 1741, 1741, 1741, 1741, 1739, 1730, 1729, 1725, 1715, 1713, 1683, 1673, 1661, 1639, 1630, 1614, 1614, 1606, 1601, 1599, 1599, 1597, 1586, 1572, 1571, 1571, 1570, 1508, 1469, 1461, 1433, 1422, 1375, 1373, 1370, 1369, 1369, 1369, 1369, 1351, 1349, 1347, 1343, 1343, 1333, 1333, 1333, 1333, 1331, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1329, 1327, 1327, 1327, 1327, 1327, 1327, 1327, 1325, 1323, 1320, 1320, 1320, 1320, 1320, 1318, 1303, 1303, 1301, 1301, 1301, 1299, 1295, 1293, 1293, 1293, 1291, 1285, 1285, 1285, 1283, 1283, 1283, 1283, 1283, 1282, 1282, 1281, 1281, 1281, 1278, 1278, 1277, 1276, 1275, 1273, 1269, 1267, 1267, 1263, 1261, 1261, 1259, 1258, 1257, 1254, 1247, 1245, 1242, 1241, 1237, 1231, 1229, 1221, 1217, 1217, 1215, 1210, 1195, 1193, 1191, 1191, 1187, 1187, 1180, 1179, 1178, 1173, 1171, 1153, 1147, 1143, 1139, 1131, 1131, 1127, 1122, 1121, 1119, 1116, 1113, 1110, 1101, 1101, 1099, 1089, 1088, 1073, 1073, 1070, 1067, 1062, 1056, 1053, 1051, 1048, 1048, 1048, 1041, 1041, 1041, 1040, 1040, 1039, 1037, 1036, 1025, 1022, 1018, 1018, 1018, 1018, 1018, 1017, 1017, 1017, 1017, 1017, 1017, 1017, 1017, 1017, 1017, 1016, 1016, 1016, 1015, 1015, 1015, 1015, 1015, 1015, 1015, 1015, 1014, 1014, 1014, 1011, 998, 996, 995, 990, 982, 978, 977, 975, 975, 966, 965, 964, 958, 957, 956, 953, 951, 951, 948, 947, 946, 944, 943, 942, 941, 941, 941, 941, 941, 941, 941, 941, 940, 939, 939, 939, 939, 939, 939, 939, 939, 939, 939, 939, 937, 937, 937, 937, 937, 936, 934, 934, 932, 929, 929, 928, 928, 927, 926, 921, 920, 920, 919, 916, 915, 914, 913, 912, 911, 911, 911, 911, 911, 910, 910, 910, 909, 909, 909, 908, 908, 908, 908, 908, 908, 907, 904, 904, 901, 897, 896, 895, 895, 895, 895, 893, 892, 891, 889, 889, 889, 888, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 887, 885, 885, 885, 885, 885, 885, 885, 885, 885, 885, 885, 878, 877, 875, 874, 873, 873, 871, 871, 870, 869, 869, 868, 868, 866, 863, 859, 858, 857, 857, 855, 855, 854, 851, 851, 851, 851, 851, 851, 851, 851, 851, 849, 849, 849, 849, 849, 849, 849, 849, 849, 849, 849, 849, 849, 849, 847, 847, 847, 847, 847, 847, 847, 847, 847, 847, 846, 839, 839, 838, 837, 833, 832, 828, 827, 827, 824, 823, 822, 821, 819, 817, 815, 815, 815, 815, 815, 815, 815, 813, 813, 812, 810, 809, 806, 804, 804, 803, 803, 803, 802, 802, 802, 801, 801, 800, 797, 797, 795, 795, 794, 793, 792, 789, 789, 788, 788, 787, 787, 786, 786, 785, 785, 783, 783, 783, 783, 783, 782, 781, 781, 781, 781, 781, 780, 780, 779, 777, 777, 775, 774, 773, 772, 769, 769, 768, 767, 767, 767, 765, 765, 765, 765, 765, 765, 765, 765, 765, 765, 764, 763, 763, 763, 763, 763, 763, 763, 763, 763, 763, 763, 763, 763, 762, 762, 762, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 761, 758, 755, 753, 752, 752, 751, 750, 748, 747, 747, 744, 740, 740, 740, 740, 739, 737, 736, 736, 735, 735, 732, 729, 729, 727, 726, 725, 723, 723, 723, 722, 722, 721, 721, 721, 720, 718, 718, 715, 714, 714, 714, 713, 713, 712, 711, 711, 711, 711, 711, 711, 708, 707, 706, 706, 706, 706, 705, 705, 703, 702, 702, 698, 698, 695, 694, 694, 694, 693, 693, 692, 690, 690, 690, 687, 687, 685, 684, 684, 682, 680, 679, 678, 678, 677, 677, 676, 675, 674, 674, 674, 673, 671, 670, 669, 669, 668, 668, 668, 667, 666, 666, 665, 664, 664, 664, 662, 662, 661, 660, 660, 660, 658, 658, 658, 658, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 656, 656, 656, 656, 656, 656, 656, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 654, 654, 654, 652, 652, 650, 649, 649, 646, 646, 646, 645, 644, 643, 643, 643, 643, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 641, 641, 641, 641, 641, 640, 639, 638, 638, 638, 638, 637, 637, 637, 636, 636, 634, 633, 632, 632, 630, 630, 629, 629, 629, 629, 628, 628, 628, 627, 627, 626, 625, 625, 625, 624, 624, 624, 623, 623, 623, 623, 622, 622, 622, 622, 622, 621, 621, 620, 620, 620, 619, 619, 617, 617, 617, 617, 616, 616, 616, 616, 615, 614, 614, 614, 613, 613, 613, 613, 612, 611, 611, 610, 610, 610, 610, 609, 609, 608, 608, 607, 607, 606, 606, 606, 606, 604, 604, 604, 604, 604, 602, 602, 602, 601, 601, 600, 600, 600, 599, 598, 598, 598, 598, 598, 598, 597, 597, 597, 596, 596, 596, 596, 596, 596, 596, 595, 595, 594, 594, 592, 592, 592, 592, 591, 591, 590, 590, 589, 588, 588, 588, 588, 588, 588, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 587, 586, 586, 586, 586, 586, 586, 586, 586, 586, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 585, 584, 583, 583, 583, 583, 583, 582, 582, 582, 582, 582, 582, 582, 581, 580, 580, 580, 580, 580, 579, 579, 579, 578, 578, 578, 577, 577, 577, 576, 576, 575, 574, 574, 574, 574, 573, 573, 572, 572, 571, 571, 571, 571, 570, 570, 570, 570, 570, 570, 569, 568, 568, 568, 568, 567, 567, 567, 567, 566, 566, 566, 565, 564, 564, 564, 564, 564, 564, 564, 564, 564, 563, 563, 562, 561, 560, 560, 560, 559, 558, 557, 557, 556, 556, 556, 555, 555, 555, 554, 554, 554, 554, 553, 553, 552, 552, 552, 551, 551, 551, 551, 551, 550, 550, 550, 550, 550, 549, 549, 549, 548, 548, 547, 547, 546, 546, 546, 545, 545, 545, 544, 544, 544, 544, 544, 544, 544, 544, 544, 543, 543, 543, 542, 542, 541, 541, 540, 540, 540, 539, 538, 538, 538, 538, 538, 537, 537, 537, 536, 536, 536, 536, 535, 535, 534, 534, 534, 534, 534, 534, 533, 533, 532, 532, 532, 532, 532, 532, 532, 532, 532, 531, 531, 531, 530, 530, 529, 528, 528, 528, 528, 527, 527, 526, 526, 526, 526, 526, 526, 526, 525, 525, 525, 525, 524, 524, 524, 524, 524, 524, 524, 524, 524, 524, 524, 524, 524, 524, 523, 523, 523, 523, 523, 523, 523, 523, 522, 522, 522, 522, 522, 522, 521, 521, 521, 521, 521, 521, 521, 521, 521, 521, 521, 521, 521, 520, 520, 520, 520, 520, 520, 520, 520, 520, 519, 519, 519, 518, 518, 518, 518, 517, 517, 516, 516, 516, 516, 516, 516, 516, 515, 515, 514, 514, 514, 513, 513, 512, 512, 512, 512, 511, 510, 510, 510, 510, 509, 509, 509, 509, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 508, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 507, 506, 506, 506, 506, 506, 506, 506, 506, 506, 505, 505, 505, 505, 504, 504, 504, 503, 503, 503, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 501, 501, 501, 501, 500, 500, 500, 500, 500, 499, 499, 498, 498, 498, 498, 498, 496, 496, 496, 496, 496, 496, 496, 496, 496, 496, 495, 495, 494, 494, 494, 494, 494, 494, 493, 493, 492, 492, 492, 492, 492, 492, 492, 492, 492, 490, 490, 490, 490, 490, 490, 490, 490, 489, 489, 488, 488, 488, 488, 488, 488, 487, 487, 487, 487, 486, 486, 486, 486, 486, 486, 486, 486, 485, 485, 485, 484, 484, 484, 484, 484, 484, 482, 482, 482, 482, 482, 482, 480, 480, 480, 480, 480, 480, 479, 479, 478, 478, 478, 477, 477, 477, 477, 477, 476, 476, 476, 476, 476, 476, 476, 476, 476, 476, 475, 475, 475, 475, 475, 474, 474, 474, 474, 474, 474, 474, 474, 474, 474, 472, 472, 472, 472, 472, 472, 472, 472, 472, 471, 471, 471, 470, 470, 470, 470, 470, 470, 469, 469, 469, 469, 469, 469, 468, 468, 468, 468, 468, 468, 467, 467, 467, 467, 467, 467, 466, 466, 466, 466, 466, 466, 466, 466, 466, 465, 465, 465, 465, 465, 465, 465, 465, 465, 464, 464, 464, 464, 464, 464, 464, 463, 463, 463, 462, 462, 462, 462, 462, 462, 462, 461, 460, 460, 460, 460, 460, 460, 460, 459, 459, 459, 458, 458, 458, 458, 458, 458, 458, 458, 458, 458, 457, 456, 456, 456, 456, 456, 456, 455, 455, 455, 455, 455, 455, 454, 454, 454, 453, 453, 453, 453, 453, 453, 453, 453, 453, 452, 452, 452, 452, 452, 452, 452, 451, 451, 450, 450, 450, 450, 450, 450, 450, 449, 449, 449, 449, 449, 449, 449, 448, 448, 448, 448, 447, 446, 446, 446, 446, 446, 446, 445, 445, 445, 444, 444, 444, 444, 444, 444, 444, 443, 443, 443, 443, 443, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 442, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 440, 439, 439, 438, 438, 438, 438, 438, 438, 438, 438, 438, 438, 437, 437, 436, 436, 436, 436, 436, 436, 436, 435, 435, 435, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 434, 433, 433, 433, 433, 433, 432, 432, 432, 432, 432, 430, 430, 430, 430, 430, 430, 430, 430, 429, 429, 428, 428, 428, 428, 428, 428, 428, 428, 427, 427, 427, 427, 427, 426, 426, 426, 426, 426, 426, 426, 426, 425, 425, 425, 424, 424, 424, 424, 424, 424, 423, 423, 423, 422, 422, 422, 422, 422, 422, 422, 422, 421, 421, 421, 421, 421, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 420, 419, 419, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 417, 417, 417, 417, 416, 416, 416, 416, 416, 416, 416, 416, 415, 415, 415, 415, 415, 415, 415, 415, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 413, 413, 412, 412, 412, 412, 412, 412, 412, 411, 411, 411, 411, 411, 410, 410, 410, 410, 410, 410, 409, 409, 409, 409, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 408, 407, 407, 407, 407, 407, 407, 407, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 406, 405, 405, 405, 405, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 404, 403, 403, 403, 403, 402, 402, 402, 402, 402, 402, 402, 402, 401, 401, 401, 401, 401, 401, 400, 400, 400, 400, 400, 400, 400, 400, 400, 399, 398, 398, 398, 398, 398, 398, 398, 398, 398, 398, 397, 397, 397, 397, 397, 397, 396, 396, 396, 396, 396, 396, 396, 396, 396, 395, 395, 395, 395, 395, 394, 394, 394, 394, 394, 394, 394, 393, 393, 393, 393, 393, 392, 392, 392, 392, 392, 392, 392, 392, 392, 391, 391, 391, 390, 390, 390, 390, 388, 388, 388, 388, 388, 388, 388, 388, 388, 388, 387, 387, 387, 387, 386, 386, 386, 386, 386, 386, 385, 385, 385, 385, 384, 384, 384, 383, 383, 382, 382, 382, 382, 381, 381, 381, 381, 381, 381, 380, 380, 380, 380, 380, 380, 379, 379, 379, 379, 378, 378, 378, 378, 378, 378, 378, 377, 377, 376, 376, 376, 376, 376, 375, 375, 375, 374, 374, 374, 374, 374, 374, 374, 374, 374, 373, 373, 373, 372, 372, 371, 371, 371, 371, 370, 370, 370, 370, 370, 369, 369, 368, 368, 368, 368, 368, 368, 368, 368, 368, 367, 367, 366, 366, 366, 366, 365, 365, 365, 365, 364, 364, 364, 364, 364, 364, 363, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 361, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 359, 359, 359, 358, 358, 358, 358, 358, 358, 358, 357, 357, 357, 357, 357, 356, 356, 356, 355, 355, 355, 355, 355, 355, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 354, 353, 353, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 352, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 351, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 349, 349, 349, 349, 348, 348, 348, 348, 348, 348, 347, 347, 347, 347, 347, 347, 347, 346, 346, 346, 346, 346, 346, 346, 346, 346, 345, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 343, 343, 343, 343, 342, 342, 342, 342, 342, 342, 341, 341, 341, 341, 340, 340, 340, 340, 340, 340, 339, 339, 339, 339, 339, 338, 338, 338, 338, 338, 338, 338, 338, 338, 337, 336, 336, 336, 334, 334, 334, 334, 334, 334, 334, 334, 333, 333, 333, 333, 333, 333, 333, 333, 332, 332, 332, 331, 331, 331, 331, 331, 330, 330, 330, 330, 330, 330, 330, 330, 329, 329, 329, 329, 328, 328, 328, 328, 327, 327, 327, 327, 327, 327, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 326, 325, 324, 324, 323, 323, 322, 322, 322, 322, 322, 322, 322, 322, 321, 321, 321, 320, 320, 320, 320, 320, 320, 320, 320, 320, 318, 318, 318, 318, 317, 316, 314, 314, 314, 314, 314, 314, 313, 313, 313, 313, 312, 312, 311, 311, 311, 311, 311, 311, 311, 311, 310, 310, 310, 310, 309, 309, 309, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 308, 307, 307, 307, 306, 306, 306, 306, 305, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 303, 303, 303, 302, 302, 302, 302, 302, 302, 302, 302, 301, 301, 301, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 299, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 298, 297, 297, 297, 297, 297, 296, 296, 296, 296, 296, 295, 295, 295, 295, 295, 295, 295, 294, 294, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 291, 291, 291, 291, 291, 290, 290, 290, 290, 289, 289, 289, 289, 288, 288, 288, 287, 287, 287, 286, 286, 286, 286, 286, 285, 284, 284, 284, 283, 283, 283, 283, 282, 282, 282, 282, 281, 281, 281, 281, 281, 281, 281, 281, 281, 280, 279, 279, 279, 279, 278, 278, 278, 278, 278, 278, 278, 277, 277, 277, 277, 277, 276, 276, 276, 276, 276, 276, 275, 275, 275, 275, 275, 275, 275, 275, 275]\n",
      "Sucessfully add edges: 175\tPrune edges: 1524\tFail to add edges: 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data_files/theia.json\", \"r\") as json_file:\n",
    "    GT_mal = set(json.load(json_file))\n",
    "\n",
    "data = df\n",
    "\n",
    "phrases,labels,edges,mapp,mapidx = prepare_graph(data)\n",
    "csv_path = \"../../flash-add-edge/theia_test.csv\"\n",
    "phrases, labels, edges, mapp, mapidx = add_csv_edges_efficient(\n",
    "    phrases, labels, edges, mapp, mapidx, csv_path\n",
    ")\n",
    "\n",
    "nodes = []\n",
    "for i, x in enumerate(phrases):\n",
    "    embedding = infer(x)\n",
    "    nodes.append(embedding)\n",
    "    \n",
    "nodes = np.array(nodes)\n",
    "et = time.time()\n",
    "\n",
    "all_ids = list(data['actorID']) + list(data['objectID'])\n",
    "all_ids = set(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-18T12:07:54.266454Z",
     "iopub.status.busy": "2025-12-18T12:07:54.266185Z",
     "iopub.status.idle": "2025-12-18T12:08:32.474638Z",
     "shell.execute_reply": "2025-12-18T12:08:32.473720Z"
    },
    "executionInfo": {
     "elapsed": 15919,
     "status": "ok",
     "timestamp": 1673572401286,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "DsLlVS6zpox5",
    "outputId": "93d85078-5348-4225-e179-162b682ec426",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 25317, True Negatives: 317231, False Positives: 542, False Negatives: 42\n",
      "Precision: 0.98, Recall: 1.0, Fscore: 0.99\n"
     ]
    }
   ],
   "source": [
    "graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "for m_n in range(20):\n",
    "  # model.load_state_dict(torch.load(f'trained_weights/theia/lword2vec_gnn_theia{m_n}_E3.pth',map_location=torch.device('cpu')))\n",
    "  # model.load_state_dict(torch.load(f'lword2vec_gnn_theia{m_n}_E3.pth',map_location=torch.device('cpu')))\n",
    "  model.load_state_dict(torch.load(f'lword2vec_gnn_theia{m_n}_E3.pth', map_location=device))\n",
    "  loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000)    \n",
    "  for subg in loader:\n",
    "      model.eval()\n",
    "      out = model(subg.x, subg.edge_index)\n",
    "\n",
    "      sorted, indices = out.sort(dim=1,descending=True)\n",
    "      conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "      conf = (conf - conf.min()) / conf.max()\n",
    "    \n",
    "      pred = indices[:,0]\n",
    "      cond = (pred == subg.y) & (conf > 0.53)\n",
    "      subg.n_id = subg.n_id.to(device)\n",
    "      flag[subg.n_id[cond]] = torch.logical_and(flag[subg.n_id[cond]], torch.tensor([False]*len(flag[subg.n_id[cond]]), dtype=torch.bool).to(device))\n",
    "\n",
    "index = utils.mask_to_index(flag).tolist()\n",
    "ids = set([mapp[x] for x in index])\n",
    "alerts = helper(set(ids),set(all_ids),GT_mal,edges,mapp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T12:08:32.477122Z",
     "iopub.status.busy": "2025-12-18T12:08:32.476903Z",
     "iopub.status.idle": "2025-12-18T12:08:32.485427Z",
     "shell.execute_reply": "2025-12-18T12:08:32.484841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def traverse(ids, mapping, edges, hops, visited=None):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "\n",
    "    neighbors = set()\n",
    "    for src, dst in zip(edges[0], edges[1]):\n",
    "        src_mapped, dst_mapped = mapping[src], mapping[dst]\n",
    "\n",
    "        if (src_mapped in ids and dst_mapped not in visited) or \\\n",
    "           (dst_mapped in ids and src_mapped not in visited):\n",
    "            neighbors.add(src_mapped)\n",
    "            neighbors.add(dst_mapped)\n",
    "\n",
    "        visited.add(src_mapped)\n",
    "        visited.add(dst_mapped)\n",
    "\n",
    "    neighbors.difference_update(ids) \n",
    "    return ids.union(traverse(neighbors, mapping, edges, hops - 1, visited))\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def find_connected_alerts(start_alert, mapping, edges, depth, remaining_alerts):\n",
    "    connected_path = traverse({start_alert}, mapping, edges, depth)\n",
    "    return connected_path.intersection(remaining_alerts)\n",
    "\n",
    "def generate_incident_graphs(alerts, edges, mapping, depth):\n",
    "    incident_graphs = []\n",
    "    remaining_alerts = set(alerts)\n",
    "\n",
    "    while remaining_alerts:\n",
    "        alert = remaining_alerts.pop()\n",
    "        connected_alerts = find_connected_alerts(alert, mapping, edges, depth, remaining_alerts)\n",
    "\n",
    "        if len(connected_alerts) > 1:\n",
    "            incident_graphs.append(connected_alerts)\n",
    "            remaining_alerts -= connected_alerts\n",
    "\n",
    "    return incident_graphs\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "flash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
